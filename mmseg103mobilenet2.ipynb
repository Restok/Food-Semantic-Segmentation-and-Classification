{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "num_gpus = 4\n",
    "classes = (\"Background\", \"Meat\", \"Nuts/seeds\", \"Eggs\", \"Beans/lentils/peas\", \"Fruit\", \"Grain\", \"Vegetables\", \"Dairy\", \"Sauce/Spread\", \"Soup/Drink\")\n",
    "palette = np.random.randint(0, 255, size=(len(classes), 3))\n",
    "palette[0, :] = 0\n",
    "print(len(palette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/hli5/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config\n",
    "import mmcv\n",
    "cfg = Config.fromfile('./mmsegmentation/configs/deeplabv3plus/deeplabv3plus_r101-d8_512x512_40k_foodseg_with_label.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"deeplabv3plus_mobilenet_multi_food103_40k_together\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='MultiEncoderDecoder',\n",
      "    pretrained='open-mmlab://contrib/mobilenet_v3_large',\n",
      "    backbone=dict(\n",
      "        type='MobileNetV3',\n",
      "        arch='large',\n",
      "        out_indices=(1, 3, 16),\n",
      "        norm_cfg=dict(type='SyncBN', eps=0.001, requires_grad=True)),\n",
      "    decode_head=dict(\n",
      "        type='MultiDepthwiseSeparableASPPHead',\n",
      "        in_channels=960,\n",
      "        in_index=2,\n",
      "        channels=128,\n",
      "        dilations=(1, 12, 24, 36),\n",
      "        c1_in_channels=16,\n",
      "        c1_channels=48,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=11,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(type='CombinedCrossEntropyLoss', loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=960,\n",
      "        in_index=2,\n",
      "        channels=128,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=11,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'ADE20KDataset'\n",
      "data_root = './FoodSeg103/Images'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "crop_size = (512, 512)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "    dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', prob=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(2048, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=12,\n",
      "    train=dict(\n",
      "        type='ADE20KDataset',\n",
      "        data_root='./FoodSeg103/Images',\n",
      "        img_dir='img_dir_edited/train',\n",
      "        ann_dir='ann_dir_edited/train',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', reduce_zero_label=False),\n",
      "            dict(type='Resize', img_scale=(2048, 512), ratio_range=(0.5, 2.0)),\n",
      "            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', prob=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='ADE20KDataset',\n",
      "        data_root='./FoodSeg103/Images',\n",
      "        img_dir='img_dir_edited/test',\n",
      "        ann_dir='ann_dir_edited/test',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='ADE20KDataset',\n",
      "        data_root='./FoodSeg103/Images',\n",
      "        img_dir='img_dir_edited/test',\n",
      "        ann_dir='ann_dir_edited/test',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(2048, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "log_config = dict(\n",
      "    interval=100, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=40000)\n",
      "checkpoint_config = dict(by_epoch=False, interval=5000, save_optimizer=True)\n",
      "evaluation = dict(interval=50, metric='mIoU', pre_eval=True)\n",
      "seed = 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "norm_cfg = dict(type='SyncBN', eps=0.001, requires_grad=True)\n",
    "cfg.model.backbone=dict(\n",
    "        type='MobileNetV3',\n",
    "        arch='large',\n",
    "        out_indices=(1, 3, 16),\n",
    "        norm_cfg=norm_cfg)\n",
    "cfg.model.pretrained = 'open-mmlab://contrib/mobilenet_v3_large'\n",
    "cfg.model.decode_head.num_classes = len(classes)\n",
    "cfg.model.auxiliary_head.num_classes = len(classes)\n",
    "cfg.model.decode_head.in_channels = 960\n",
    "cfg.model.decode_head.in_index = 2\n",
    "cfg.model.decode_head.channels = 128\n",
    "cfg.model.decode_head.c1_in_channels = 16\n",
    "cfg.model.auxiliary_head.channels = 128\n",
    "cfg.model.auxiliary_head.in_channels = 960\n",
    "cfg.model.auxiliary_head.in_index = 2\n",
    "cfg.data.samples_per_gpu = 4\n",
    "cfg.data.workers_per_gpu=12\n",
    "\n",
    "\n",
    "cfg.runner.max_iters = 80000\n",
    "cfg.log_config = dict(\n",
    "    interval=100,\n",
    "    hooks=[\n",
    "        dict(type='TextLoggerHook', by_epoch=False)\n",
    "    ]\n",
    ")\n",
    "cfg.evaluation.interval = 5000\n",
    "cfg.checkpoint_config.interval = 5000\n",
    "cfg.checkpoint_config.save_optimizer = True\n",
    "# cfg.model.backbone.frozen_stages=1\n",
    "\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "config_path = \"mmsegmentation/configs/food103configs/\" + name + \".py\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mmsegmentation/configs/food103configs/deeplabv3plus_mobilenet_multi_food103_40k_together.py'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mmsegmentation/tools/dist_train.sh {config_path} {num_gpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "work_dir = './work_dirs/' + name\n",
    "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n",
    "assert os.path.isfile(\n",
    "    checkpoint_file), '`{}` not exist'.format(checkpoint_file)\n",
    "checkpoint_file = os.path.abspath(checkpoint_file)\n",
    "checkpoint_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from mmcv.runner import load_checkpoint\n",
    "import mmcv.visualization.image as mmcv_image\n",
    "# fix for colab\n",
    "\n",
    "def imshow(img, win_name='', wait_time=0): plt.figure(\n",
    "    figsize=(50, 50)); plt.imshow(img)\n",
    "\n",
    "\n",
    "mmcv_image.imshow = imshow\n",
    "from mmsegmentation.mmseg.apis import inference_segmentor, init_segmentor\n",
    "\n",
    "\n",
    "config_fname = config_path\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_segmentor(config_fname, checkpoint_file)\n",
    "model.CLASSES = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmseg.datasets.pipelines import Compose\n",
    "# load and display an image with Matplotlib\n",
    "from PIL import Image\n",
    "def show_result_pyplot(model,\n",
    "                       img,\n",
    "                       result,\n",
    "                       palette=None,\n",
    "                       fig_size=(20, 8),\n",
    "                       opacity=0.5,\n",
    "                       title='',\n",
    "                       block=True,\n",
    "                       show_legend=False):\n",
    "    \"\"\"Visualize the segmentation results on the image.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded segmentor.\n",
    "        img (str or np.ndarray): Image filename or loaded image.\n",
    "        result (list): The segmentation result.\n",
    "        palette (list[list[int]]] | None): The palette of segmentation\n",
    "            map. If None is given, random palette will be generated.\n",
    "            Default: None\n",
    "        fig_size (tuple): Figure size of the pyplot figure.\n",
    "        opacity(float): Opacity of painted segmentation map.\n",
    "            Default 0.5.\n",
    "            Must be in (0, 1] range.\n",
    "        title (str): The title of pyplot figure.\n",
    "            Default is ''.\n",
    "        block (bool): Whether to block the pyplot figure.\n",
    "            Default is True.\n",
    "    \"\"\"\n",
    "    _, axes = plt.subplots(nrows=1, ncols=3, figsize=fig_size)\n",
    "    original_image = Image.open(img)\n",
    "    file_id = img.split('/')[-1].split('.')[0] + '.png'\n",
    "    gt_path = 'FoodSeg103/Images/ann_dir_edited/test/'+file_id\n",
    "    gt_labels = Image.open(gt_path).convert('RGB')\n",
    "    gt_labels = np.array(gt_labels, dtype=np.uint8)\n",
    "    gt_labels_ids = np.unique(gt_labels)\n",
    "    for i in gt_labels_ids:\n",
    "        gt_labels = np.where(gt_labels == [i,i,i], palette[int(i)], gt_labels)\n",
    "    gt_labels = gt_labels/255\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[1].imshow(original_image)\n",
    "    axes[1].imshow(gt_labels, alpha=opacity)\n",
    "    \n",
    "    if hasattr(model, 'module'):\n",
    "        model = model.module\n",
    "    img = model.show_result(\n",
    "        img, result, palette=palette, show=False, opacity=opacity)\n",
    "    uniques_set = set(np.unique(result))\n",
    "    uniques_set.update(set(gt_labels_ids.flatten()))\n",
    "    if(show_legend):\n",
    "        custom_lines = []\n",
    "        labels = []\n",
    "        for i in uniques_set:\n",
    "            labels.append(model.CLASSES[i])\n",
    "            rgb_color = [v/255 for v in palette[i]]\n",
    "            custom_lines.append(plt.Line2D([0], [0], color=tuple(rgb_color), lw=4))\n",
    "        plt.legend(custom_lines, labels)\n",
    "    axes[2].imshow(mmcv.bgr2rgb(img))\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=block)\n",
    "\n",
    "class LoadImage:\n",
    "    \"\"\"A simple pipeline to load image.\"\"\"\n",
    "\n",
    "    def __call__(self, results):\n",
    "        \"\"\"Call function to load images into results.\n",
    "\n",
    "        Args:\n",
    "            results (dict): A result dict contains the file name\n",
    "                of the image to be read.\n",
    "\n",
    "        Returns:\n",
    "            dict: ``results`` will be returned containing loaded image.\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(results['img'], str):\n",
    "            results['filename'] = results['img']\n",
    "            results['ori_filename'] = results['img']\n",
    "        else:\n",
    "            results['filename'] = None\n",
    "            results['ori_filename'] = None\n",
    "        img = mmcv.imread(results['img'])\n",
    "        results['img'] = img\n",
    "        results['img_shape'] = img.shape\n",
    "        results['ori_shape'] = img.shape\n",
    "        return results\n",
    "\n",
    "\n",
    "def inference_segmentor(model, img):\n",
    "    \"\"\"Inference image(s) with the segmentor.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded segmentor.\n",
    "        imgs (str/ndarray or list[str/ndarray]): Either image files or loaded\n",
    "            images.\n",
    "\n",
    "    Returns:\n",
    "        (list[Tensor]): The segmentation result.\n",
    "    \"\"\"\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "    # build the data pipeline\n",
    "    test_pipeline = [LoadImage()] + cfg.data.test.pipeline[1:]\n",
    "    test_pipeline = Compose(test_pipeline)\n",
    "    # prepare data\n",
    "    data = dict(img=img)\n",
    "    data = test_pipeline(data)\n",
    "    data = collate([data], samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "    else:\n",
    "        data['img_metas'] = [i.data[0] for i in data['img_metas']]\n",
    "    # forward the model\n",
    "    with torch.no_grad():\n",
    "        result, labels = model(return_loss=False, rescale=True, **data)\n",
    "\n",
    "    return result, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "labels_db = pd.read_csv(\"food103labels.csv\",sep=',')\n",
    "LABELS = list(model.CLASSES)[1:]\n",
    "count = 0\n",
    "def get_label(file_path):\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    numpy_array = labels_db.loc[labels_db['filename'] == file_name][LABELS].to_numpy().astype('int64')\n",
    "    return numpy_array\n",
    "def to_one_hot(preds, classes):\n",
    "    labels_classification = []\n",
    "    for i in range(len(preds)):\n",
    "        if(preds[i] == 1):\n",
    "            labels_classification.append(classes[i+1])\n",
    "    return \", \".join(labels_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a single image and show the results\n",
    "file_list = glob.glob(\"FoodSeg103/Images/img_dir_edited/test/*.jpg\")\n",
    "import random\n",
    "for i in range(2):\n",
    "    img = random.choice(file_list)\n",
    "    result, pred_labels = inference_segmentor(model, img)\n",
    "    pred_labels = torch.nn.Sigmoid()(pred_labels)\n",
    "    pred_labels[pred_labels>=0.5] = 1\n",
    "    pred_labels[pred_labels<0.5] = 0\n",
    "    gt_labels = to_one_hot(get_label(img).squeeze(),model.CLASSES)\n",
    "    title = \"Predicted: \" + to_one_hot(pred_labels, model.CLASSES) + \"\\n Ground truth: \" + gt_labels\n",
    "    show_result_pyplot(model, img, result, palette=palette, title=title, show_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = work_dir + \"/result\"\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_acc = np.zeros(len(LABELS))\n",
    "all_predictions = np.zeros(shape=(len(file_list), len(LABELS)))\n",
    "all_gt = np.zeros(shape=(len(file_list), len(LABELS)))\n",
    "def get_label(file_path):    \n",
    "    file_name = file_path.split('/')[-1]\n",
    "    numpy_array = labels_db.loc[labels_db['filename'] == file_name][LABELS].to_numpy().astype('int64')\n",
    "    return numpy_array\n",
    "for file in file_list:\n",
    "    mask, preds = inference_segmentor(model, file)\n",
    "    preds = torch.nn.Sigmoid()(preds)\n",
    "    preds[preds>=0.5] = 1\n",
    "    preds[preds<0.5] = 0\n",
    "    preds = preds.cpu().numpy()\n",
    "    gt_label = get_label(file).squeeze()\n",
    "    np_acc = np.add(preds == gt_label, np_acc)\n",
    "    all_predictions[count, :] = preds\n",
    "    all_gt[count, :] = gt_label\n",
    "    count+=1\n",
    "    print(count, end='\\r')\n",
    "np_acc = np_acc/len(file_list)\n",
    "c = 0\n",
    "for l in LABELS:\n",
    "    print(f\"Accuracy of {l}: {np_acc[c]}\")\n",
    "    c = c+1\n",
    "print(np.average(np_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.core.evaluation import mean_ap\n",
    "\n",
    "mean_average_precision = mean_ap.mAP(all_predictions, all_gt)\n",
    "print(mean_average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!./mmsegmentation/tools/dist_test.sh {config_path} {checkpoint_file} 4 --show-dir {save_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('food2022': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ceed115e2785451e93a6892c02d3760f831f2e8ebb6fa3a261251c7741db1606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
