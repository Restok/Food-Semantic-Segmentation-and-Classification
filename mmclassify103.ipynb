{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "num_gpus = 4\n",
    "classes = (\"Meat\", \"Nuts/seeds\", \"Eggs\", \"Beans/lentils/peas\", \"Fruit\", \"Grain\", \"Vegetables\", \"Dairy\", \"Dessert\", \"Sauce/Spread\", \"Soup\", \"Drink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/hli5/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('mmclassification/configs/resnet/resnet101_4xb16_foodseg103.py')\n",
    "name = \"mobile_v3_l_4xb16_foodseg103\"\n",
    "import os\n",
    "work_dir = './work_dirs/' + name\n",
    "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n",
    "if(not osp.exists(checkpoint_file)):\n",
    "    checkpoint_file = 'https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth'\n",
    "    print(\"Loading pretrained weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'FoodSeg103'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', size=224),\n",
      "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='ToTensor', keys=['gt_label']),\n",
      "    dict(type='Collect', keys=['img', 'gt_label'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', size=(256, -1)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=16,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/train.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', size=224),\n",
      "            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='ToTensor', keys=['gt_label']),\n",
      "            dict(type='Collect', keys=['img', 'gt_label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/test.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', size=(256, -1)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/test.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', size=(256, -1)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric=['mAP', 'ACC'])\n",
      "checkpoint_config = dict(interval=10)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='MobileNetV3',\n",
      "        arch='large',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='./work_dirs/mobile_v3_l_4xb16_foodseg103/latest.pth',\n",
      "            prefix='backbone')),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='MultiLabelLinearClsHead',\n",
      "        num_classes=12,\n",
      "        in_channels=960,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0, use_sigmoid=True)))\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    lr=0.001,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({'.backbone.classifier': dict(lr_mult=10)})))\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(policy='step', step=20, gamma=0.1)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.model.head.num_classes = len(classes)\n",
    "\n",
    "# Load the pre-trained model's checkpoint.\n",
    "cfg.model.backbone = dict(type='MobileNetV3', arch='large')\n",
    "cfg.model.backbone['init_cfg'] = dict(type='Pretrained', checkpoint=checkpoint_file, prefix='backbone')\n",
    "cfg.model.head.in_channels=960\n",
    "\n",
    "# Specify sample size and number of workers.\n",
    "cfg.data.samples_per_gpu = 16\n",
    "cfg.checkpoint_config = dict(interval=10)\n",
    "cfg.log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
    "cfg.data.workers_per_gpu = 4\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=40)\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "config_path = \"mmclassification/configs/food103configs/\" + name + \".py\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "/nfs/nfs9/home/nobackup/hli5/FoodCV/mmclassification/mmcls/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/nfs/nfs9/home/nobackup/hli5/FoodCV/mmclassification/mmcls/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/nfs/nfs9/home/nobackup/hli5/FoodCV/mmclassification/mmcls/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/nfs/nfs9/home/nobackup/hli5/FoodCV/mmclassification/mmcls/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "2022-06-27 16:40:56,559 - mmcls - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.13 (default, Mar 28 2022, 11:38:47) [GCC 7.5.0]\n",
      "CUDA available: True\n",
      "GPU 0: NVIDIA TITAN V\n",
      "GPU 1: Quadro P6000\n",
      "GPU 2,3: NVIDIA TITAN X (Pascal)\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 11.7, V11.7.64\n",
      "GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\n",
      "PyTorch: 1.8.0+cu101\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.9.0+cu101\n",
      "OpenCV: 4.6.0\n",
      "MMCV: 1.5.3\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 10.1\n",
      "MMClassification: 0.23.1+cc436a5\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-06-27 16:40:56,559 - mmcls - INFO - Distributed training: True\n",
      "2022-06-27 16:40:56,835 - mmcls - INFO - Config:\n",
      "dataset_type = 'FoodSeg103'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', size=224),\n",
      "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='ToTensor', keys=['gt_label']),\n",
      "    dict(type='Collect', keys=['img', 'gt_label'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', size=(256, -1)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=16,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/train.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', size=224),\n",
      "            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='ToTensor', keys=['gt_label']),\n",
      "            dict(type='Collect', keys=['img', 'gt_label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/test.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', size=(256, -1)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/test.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', size=(256, -1)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric=['mAP', 'ACC'])\n",
      "checkpoint_config = dict(interval=10)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='MobileNetV3',\n",
      "        arch='large',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth',\n",
      "            prefix='backbone')),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='MultiLabelLinearClsHead',\n",
      "        num_classes=12,\n",
      "        in_channels=960,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0, use_sigmoid=True)))\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    lr=0.001,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({'.backbone.classifier': dict(lr_mult=10)})))\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(policy='step', step=20, gamma=0.1)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=40)\n",
      "work_dir = './work_dirs/mobile_v3_l_4xb16_foodseg103'\n",
      "gpu_ids = range(0, 4)\n",
      "\n",
      "2022-06-27 16:40:59,998 - mmcls - INFO - Set random seed to 495178045, deterministic: False\n",
      "/nobackup/hli5/miniconda3/envs/food2022/lib/python3.8/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n",
      "/nobackup/hli5/miniconda3/envs/food2022/lib/python3.8/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n",
      "/nobackup/hli5/miniconda3/envs/food2022/lib/python3.8/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n",
      "/nobackup/hli5/miniconda3/envs/food2022/lib/python3.8/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth\n",
      "2022-06-27 16:41:00,093 - mmcls - INFO - initialize MobileNetV3 with init_cfg {'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth', 'prefix': 'backbone'}\n",
      "2022-06-27 16:41:00,094 - mmcv - INFO - load backbone in model from: https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth\n",
      "load checkpoint from http path: https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth\n",
      "2022-06-27 16:41:00,149 - mmcls - INFO - initialize MultiLabelLinearClsHead with init_cfg {'type': 'Normal', 'layer': 'Linear', 'std': 0.01}\n",
      "2022-06-27 16:41:54,912 - mmcls - INFO - Start running, host: hli5@manectric, work_dir: /nfs/nfs9/home/nobackup/hli5/FoodCV/work_dirs/mobile_v3_l_4xb16_foodseg103\n",
      "2022-06-27 16:41:54,913 - mmcls - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-06-27 16:41:54,913 - mmcls - INFO - workflow: [('train', 1)], max: 40 epochs\n",
      "2022-06-27 16:41:54,914 - mmcls - INFO - Checkpoints will be saved to /nfs/nfs9/home/nobackup/hli5/FoodCV/work_dirs/mobile_v3_l_4xb16_foodseg103 by HardDiskBackend.\n",
      "2022-06-27 16:41:58,098 - mmcv - INFO - Reducer buckets have been rebuilt in this iteration.\n",
      "2022-06-27 16:41:59,097 - mmcls - INFO - Epoch [1][10/74]\tlr: 1.000e-03, eta: 0:20:30, time: 0.417, data_time: 0.274, memory: 737, loss: 6.8407\n",
      "2022-06-27 16:42:00,609 - mmcls - INFO - Epoch [1][20/74]\tlr: 1.000e-03, eta: 0:13:53, time: 0.150, data_time: 0.027, memory: 737, loss: 4.7520\n",
      "2022-06-27 16:42:02,141 - mmcls - INFO - Epoch [1][30/74]\tlr: 1.000e-03, eta: 0:11:42, time: 0.152, data_time: 0.003, memory: 737, loss: 4.5097\n",
      "2022-06-27 16:42:03,841 - mmcls - INFO - Epoch [1][40/74]\tlr: 1.000e-03, eta: 0:10:50, time: 0.172, data_time: 0.009, memory: 737, loss: 4.5466\n",
      "2022-06-27 16:42:05,668 - mmcls - INFO - Epoch [1][50/74]\tlr: 1.000e-03, eta: 0:10:24, time: 0.183, data_time: 0.001, memory: 737, loss: 4.3236\n",
      "2022-06-27 16:42:06,797 - mmcls - INFO - Epoch [1][60/74]\tlr: 1.000e-03, eta: 0:09:32, time: 0.111, data_time: 0.002, memory: 737, loss: 4.2643\n",
      "2022-06-27 16:42:08,165 - mmcls - INFO - Epoch [1][70/74]\tlr: 1.000e-03, eta: 0:09:06, time: 0.139, data_time: 0.007, memory: 737, loss: 4.2761\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 546.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:42:12,114 - mmcls - INFO - Epoch(val) [1][32]\tmAP: 37.2118, ACC: 0.8584\n",
      "2022-06-27 16:42:16,164 - mmcls - INFO - Epoch [2][10/74]\tlr: 1.000e-03, eta: 0:09:51, time: 0.403, data_time: 0.296, memory: 737, loss: 4.1326\n",
      "2022-06-27 16:42:17,730 - mmcls - INFO - Epoch [2][20/74]\tlr: 1.000e-03, eta: 0:09:34, time: 0.156, data_time: 0.056, memory: 737, loss: 4.1333\n",
      "2022-06-27 16:42:18,832 - mmcls - INFO - Epoch [2][30/74]\tlr: 1.000e-03, eta: 0:09:07, time: 0.111, data_time: 0.043, memory: 737, loss: 4.1745\n",
      "2022-06-27 16:42:20,521 - mmcls - INFO - Epoch [2][40/74]\tlr: 1.000e-03, eta: 0:08:59, time: 0.166, data_time: 0.025, memory: 737, loss: 3.9829\n",
      "2022-06-27 16:42:22,046 - mmcls - INFO - Epoch [2][50/74]\tlr: 1.000e-03, eta: 0:08:49, time: 0.156, data_time: 0.009, memory: 737, loss: 3.8994\n",
      "2022-06-27 16:42:23,273 - mmcls - INFO - Epoch [2][60/74]\tlr: 1.000e-03, eta: 0:08:34, time: 0.121, data_time: 0.001, memory: 737, loss: 4.0159\n",
      "2022-06-27 16:42:24,847 - mmcls - INFO - Epoch [2][70/74]\tlr: 1.000e-03, eta: 0:08:27, time: 0.158, data_time: 0.014, memory: 737, loss: 3.8648\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 575.3 task/s, elapsed: 3s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:42:28,631 - mmcls - INFO - Epoch(val) [2][32]\tmAP: 40.4165, ACC: 0.8758\n",
      "2022-06-27 16:42:32,727 - mmcls - INFO - Epoch [3][10/74]\tlr: 1.000e-03, eta: 0:08:52, time: 0.407, data_time: 0.222, memory: 737, loss: 4.0141\n",
      "2022-06-27 16:42:33,768 - mmcls - INFO - Epoch [3][20/74]\tlr: 1.000e-03, eta: 0:08:35, time: 0.102, data_time: 0.003, memory: 737, loss: 3.7922\n",
      "2022-06-27 16:42:35,654 - mmcls - INFO - Epoch [3][30/74]\tlr: 1.000e-03, eta: 0:08:35, time: 0.192, data_time: 0.115, memory: 737, loss: 3.8156\n",
      "2022-06-27 16:42:37,096 - mmcls - INFO - Epoch [3][40/74]\tlr: 1.000e-03, eta: 0:08:27, time: 0.145, data_time: 0.077, memory: 737, loss: 3.7608\n",
      "2022-06-27 16:42:38,465 - mmcls - INFO - Epoch [3][50/74]\tlr: 1.000e-03, eta: 0:08:19, time: 0.137, data_time: 0.075, memory: 737, loss: 3.7569\n",
      "2022-06-27 16:42:39,840 - mmcls - INFO - Epoch [3][60/74]\tlr: 1.000e-03, eta: 0:08:11, time: 0.138, data_time: 0.035, memory: 737, loss: 3.7517\n",
      "2022-06-27 16:42:41,094 - mmcls - INFO - Epoch [3][70/74]\tlr: 1.000e-03, eta: 0:08:03, time: 0.125, data_time: 0.002, memory: 737, loss: 3.8968\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 574.6 task/s, elapsed: 3s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:42:45,110 - mmcls - INFO - Epoch(val) [3][32]\tmAP: 42.1997, ACC: 0.8810\n",
      "2022-06-27 16:42:48,953 - mmcls - INFO - Epoch [4][10/74]\tlr: 1.000e-03, eta: 0:08:16, time: 0.382, data_time: 0.245, memory: 737, loss: 3.7732\n",
      "2022-06-27 16:42:50,501 - mmcls - INFO - Epoch [4][20/74]\tlr: 1.000e-03, eta: 0:08:11, time: 0.155, data_time: 0.009, memory: 737, loss: 3.6491\n",
      "2022-06-27 16:42:52,539 - mmcls - INFO - Epoch [4][30/74]\tlr: 1.000e-03, eta: 0:08:12, time: 0.204, data_time: 0.096, memory: 737, loss: 3.7654\n",
      "2022-06-27 16:42:53,695 - mmcls - INFO - Epoch [4][40/74]\tlr: 1.000e-03, eta: 0:08:03, time: 0.116, data_time: 0.023, memory: 737, loss: 3.8690\n",
      "2022-06-27 16:42:54,869 - mmcls - INFO - Epoch [4][50/74]\tlr: 1.000e-03, eta: 0:07:55, time: 0.116, data_time: 0.011, memory: 737, loss: 3.6862\n",
      "2022-06-27 16:42:56,469 - mmcls - INFO - Epoch [4][60/74]\tlr: 1.000e-03, eta: 0:07:52, time: 0.160, data_time: 0.050, memory: 737, loss: 3.7154\n",
      "2022-06-27 16:42:57,948 - mmcls - INFO - Epoch [4][70/74]\tlr: 1.000e-03, eta: 0:07:48, time: 0.150, data_time: 0.033, memory: 737, loss: 3.5558\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 570.9 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:43:01,771 - mmcls - INFO - Epoch(val) [4][32]\tmAP: 43.3594, ACC: 0.8837\n",
      "2022-06-27 16:43:05,908 - mmcls - INFO - Epoch [5][10/74]\tlr: 1.000e-03, eta: 0:08:00, time: 0.413, data_time: 0.337, memory: 737, loss: 3.5492\n",
      "2022-06-27 16:43:07,212 - mmcls - INFO - Epoch [5][20/74]\tlr: 1.000e-03, eta: 0:07:54, time: 0.130, data_time: 0.067, memory: 737, loss: 3.7016\n",
      "2022-06-27 16:43:08,993 - mmcls - INFO - Epoch [5][30/74]\tlr: 1.000e-03, eta: 0:07:52, time: 0.176, data_time: 0.103, memory: 737, loss: 3.6273\n",
      "2022-06-27 16:43:10,050 - mmcls - INFO - Epoch [5][40/74]\tlr: 1.000e-03, eta: 0:07:44, time: 0.108, data_time: 0.038, memory: 737, loss: 3.6000\n",
      "2022-06-27 16:43:11,623 - mmcls - INFO - Epoch [5][50/74]\tlr: 1.000e-03, eta: 0:07:41, time: 0.155, data_time: 0.001, memory: 737, loss: 3.6397\n",
      "2022-06-27 16:43:13,161 - mmcls - INFO - Epoch [5][60/74]\tlr: 1.000e-03, eta: 0:07:37, time: 0.155, data_time: 0.004, memory: 737, loss: 3.6366\n",
      "2022-06-27 16:43:14,533 - mmcls - INFO - Epoch [5][70/74]\tlr: 1.000e-03, eta: 0:07:33, time: 0.138, data_time: 0.002, memory: 737, loss: 3.6010\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 569.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:43:18,591 - mmcls - INFO - Epoch(val) [5][32]\tmAP: 44.3773, ACC: 0.8876\n",
      "2022-06-27 16:43:22,742 - mmcls - INFO - Epoch [6][10/74]\tlr: 1.000e-03, eta: 0:07:42, time: 0.413, data_time: 0.249, memory: 737, loss: 3.6150\n",
      "2022-06-27 16:43:24,165 - mmcls - INFO - Epoch [6][20/74]\tlr: 1.000e-03, eta: 0:07:38, time: 0.143, data_time: 0.004, memory: 737, loss: 3.5607\n",
      "2022-06-27 16:43:25,725 - mmcls - INFO - Epoch [6][30/74]\tlr: 1.000e-03, eta: 0:07:35, time: 0.156, data_time: 0.002, memory: 737, loss: 3.6325\n",
      "2022-06-27 16:43:26,931 - mmcls - INFO - Epoch [6][40/74]\tlr: 1.000e-03, eta: 0:07:29, time: 0.119, data_time: 0.002, memory: 737, loss: 3.4686\n",
      "2022-06-27 16:43:28,309 - mmcls - INFO - Epoch [6][50/74]\tlr: 1.000e-03, eta: 0:07:25, time: 0.139, data_time: 0.004, memory: 737, loss: 3.5447\n",
      "2022-06-27 16:43:29,946 - mmcls - INFO - Epoch [6][60/74]\tlr: 1.000e-03, eta: 0:07:23, time: 0.162, data_time: 0.002, memory: 737, loss: 3.5213\n",
      "2022-06-27 16:43:31,268 - mmcls - INFO - Epoch [6][70/74]\tlr: 1.000e-03, eta: 0:07:19, time: 0.135, data_time: 0.004, memory: 737, loss: 3.5899\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 569.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:43:35,249 - mmcls - INFO - Epoch(val) [6][32]\tmAP: 45.1178, ACC: 0.8894\n",
      "2022-06-27 16:43:39,452 - mmcls - INFO - Epoch [7][10/74]\tlr: 1.000e-03, eta: 0:07:26, time: 0.420, data_time: 0.262, memory: 737, loss: 3.4678\n",
      "2022-06-27 16:43:41,212 - mmcls - INFO - Epoch [7][20/74]\tlr: 1.000e-03, eta: 0:07:24, time: 0.175, data_time: 0.002, memory: 737, loss: 3.5124\n",
      "2022-06-27 16:43:42,464 - mmcls - INFO - Epoch [7][30/74]\tlr: 1.000e-03, eta: 0:07:19, time: 0.125, data_time: 0.001, memory: 737, loss: 3.3803\n",
      "2022-06-27 16:43:43,648 - mmcls - INFO - Epoch [7][40/74]\tlr: 1.000e-03, eta: 0:07:14, time: 0.116, data_time: 0.002, memory: 737, loss: 3.4393\n",
      "2022-06-27 16:43:45,264 - mmcls - INFO - Epoch [7][50/74]\tlr: 1.000e-03, eta: 0:07:12, time: 0.163, data_time: 0.065, memory: 737, loss: 3.4809\n",
      "2022-06-27 16:43:46,612 - mmcls - INFO - Epoch [7][60/74]\tlr: 1.000e-03, eta: 0:07:08, time: 0.132, data_time: 0.054, memory: 737, loss: 3.4241\n",
      "2022-06-27 16:43:47,903 - mmcls - INFO - Epoch [7][70/74]\tlr: 1.000e-03, eta: 0:07:04, time: 0.132, data_time: 0.006, memory: 737, loss: 3.5763\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 560.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:43:51,707 - mmcls - INFO - Epoch(val) [7][32]\tmAP: 46.4767, ACC: 0.8911\n",
      "2022-06-27 16:43:55,726 - mmcls - INFO - Epoch [8][10/74]\tlr: 1.000e-03, eta: 0:07:09, time: 0.402, data_time: 0.287, memory: 737, loss: 3.4185\n",
      "2022-06-27 16:43:57,204 - mmcls - INFO - Epoch [8][20/74]\tlr: 1.000e-03, eta: 0:07:06, time: 0.145, data_time: 0.017, memory: 737, loss: 3.4633\n",
      "2022-06-27 16:43:58,831 - mmcls - INFO - Epoch [8][30/74]\tlr: 1.000e-03, eta: 0:07:04, time: 0.165, data_time: 0.015, memory: 737, loss: 3.4061\n",
      "2022-06-27 16:44:00,469 - mmcls - INFO - Epoch [8][40/74]\tlr: 1.000e-03, eta: 0:07:02, time: 0.164, data_time: 0.002, memory: 737, loss: 3.3136\n",
      "2022-06-27 16:44:02,004 - mmcls - INFO - Epoch [8][50/74]\tlr: 1.000e-03, eta: 0:06:59, time: 0.152, data_time: 0.001, memory: 737, loss: 3.3775\n",
      "2022-06-27 16:44:03,594 - mmcls - INFO - Epoch [8][60/74]\tlr: 1.000e-03, eta: 0:06:56, time: 0.161, data_time: 0.003, memory: 737, loss: 3.3531\n",
      "2022-06-27 16:44:04,533 - mmcls - INFO - Epoch [8][70/74]\tlr: 1.000e-03, eta: 0:06:51, time: 0.093, data_time: 0.001, memory: 737, loss: 3.5190\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 572.1 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:44:08,437 - mmcls - INFO - Epoch(val) [8][32]\tmAP: 47.5008, ACC: 0.8938\n",
      "2022-06-27 16:44:12,586 - mmcls - INFO - Epoch [9][10/74]\tlr: 1.000e-03, eta: 0:06:56, time: 0.415, data_time: 0.259, memory: 737, loss: 3.3283\n",
      "2022-06-27 16:44:14,076 - mmcls - INFO - Epoch [9][20/74]\tlr: 1.000e-03, eta: 0:06:53, time: 0.147, data_time: 0.074, memory: 737, loss: 3.4316\n",
      "2022-06-27 16:44:15,393 - mmcls - INFO - Epoch [9][30/74]\tlr: 1.000e-03, eta: 0:06:49, time: 0.131, data_time: 0.059, memory: 737, loss: 3.4094\n",
      "2022-06-27 16:44:16,783 - mmcls - INFO - Epoch [9][40/74]\tlr: 1.000e-03, eta: 0:06:46, time: 0.140, data_time: 0.005, memory: 737, loss: 3.4470\n",
      "2022-06-27 16:44:18,404 - mmcls - INFO - Epoch [9][50/74]\tlr: 1.000e-03, eta: 0:06:44, time: 0.163, data_time: 0.059, memory: 737, loss: 3.3829\n",
      "2022-06-27 16:44:19,668 - mmcls - INFO - Epoch [9][60/74]\tlr: 1.000e-03, eta: 0:06:41, time: 0.126, data_time: 0.024, memory: 737, loss: 3.4394\n",
      "2022-06-27 16:44:21,107 - mmcls - INFO - Epoch [9][70/74]\tlr: 1.000e-03, eta: 0:06:38, time: 0.144, data_time: 0.016, memory: 737, loss: 3.3549\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 555.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:44:25,010 - mmcls - INFO - Epoch(val) [9][32]\tmAP: 48.3154, ACC: 0.8947\n",
      "2022-06-27 16:44:28,903 - mmcls - INFO - Epoch [10][10/74]\tlr: 1.000e-03, eta: 0:06:40, time: 0.389, data_time: 0.261, memory: 737, loss: 3.3471\n",
      "2022-06-27 16:44:30,598 - mmcls - INFO - Epoch [10][20/74]\tlr: 1.000e-03, eta: 0:06:38, time: 0.169, data_time: 0.006, memory: 737, loss: 3.2119\n",
      "2022-06-27 16:44:31,820 - mmcls - INFO - Epoch [10][30/74]\tlr: 1.000e-03, eta: 0:06:35, time: 0.121, data_time: 0.015, memory: 737, loss: 3.4709\n",
      "2022-06-27 16:44:33,549 - mmcls - INFO - Epoch [10][40/74]\tlr: 1.000e-03, eta: 0:06:33, time: 0.173, data_time: 0.031, memory: 737, loss: 3.2373\n",
      "2022-06-27 16:44:34,865 - mmcls - INFO - Epoch [10][50/74]\tlr: 1.000e-03, eta: 0:06:30, time: 0.131, data_time: 0.004, memory: 737, loss: 3.3848\n",
      "2022-06-27 16:44:36,736 - mmcls - INFO - Epoch [10][60/74]\tlr: 1.000e-03, eta: 0:06:29, time: 0.188, data_time: 0.098, memory: 737, loss: 3.3761\n",
      "2022-06-27 16:44:37,975 - mmcls - INFO - Epoch [10][70/74]\tlr: 1.000e-03, eta: 0:06:25, time: 0.124, data_time: 0.002, memory: 737, loss: 3.2932\n",
      "2022-06-27 16:44:38,165 - mmcls - INFO - Saving checkpoint at 10 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 591.0 task/s, elapsed: 3s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:44:41,875 - mmcls - INFO - Epoch(val) [10][32]\tmAP: 49.1458, ACC: 0.8961\n",
      "2022-06-27 16:44:46,031 - mmcls - INFO - Epoch [11][10/74]\tlr: 1.000e-03, eta: 0:06:28, time: 0.412, data_time: 0.349, memory: 737, loss: 3.3941\n",
      "2022-06-27 16:44:47,273 - mmcls - INFO - Epoch [11][20/74]\tlr: 1.000e-03, eta: 0:06:25, time: 0.126, data_time: 0.035, memory: 737, loss: 3.3602\n",
      "2022-06-27 16:44:49,251 - mmcls - INFO - Epoch [11][30/74]\tlr: 1.000e-03, eta: 0:06:24, time: 0.198, data_time: 0.004, memory: 737, loss: 3.2710\n",
      "2022-06-27 16:44:50,339 - mmcls - INFO - Epoch [11][40/74]\tlr: 1.000e-03, eta: 0:06:20, time: 0.108, data_time: 0.003, memory: 737, loss: 3.2278\n",
      "2022-06-27 16:44:52,052 - mmcls - INFO - Epoch [11][50/74]\tlr: 1.000e-03, eta: 0:06:18, time: 0.170, data_time: 0.003, memory: 737, loss: 3.3679\n",
      "2022-06-27 16:44:53,449 - mmcls - INFO - Epoch [11][60/74]\tlr: 1.000e-03, eta: 0:06:16, time: 0.142, data_time: 0.004, memory: 737, loss: 3.2303\n",
      "2022-06-27 16:44:54,615 - mmcls - INFO - Epoch [11][70/74]\tlr: 1.000e-03, eta: 0:06:12, time: 0.117, data_time: 0.005, memory: 737, loss: 3.1822\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 559.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:44:58,485 - mmcls - INFO - Epoch(val) [11][32]\tmAP: 49.5732, ACC: 0.8979\n",
      "2022-06-27 16:45:02,544 - mmcls - INFO - Epoch [12][10/74]\tlr: 1.000e-03, eta: 0:06:14, time: 0.404, data_time: 0.317, memory: 737, loss: 3.2396\n",
      "2022-06-27 16:45:04,232 - mmcls - INFO - Epoch [12][20/74]\tlr: 1.000e-03, eta: 0:06:12, time: 0.167, data_time: 0.003, memory: 737, loss: 3.2225\n",
      "2022-06-27 16:45:05,617 - mmcls - INFO - Epoch [12][30/74]\tlr: 1.000e-03, eta: 0:06:09, time: 0.141, data_time: 0.059, memory: 737, loss: 3.2474\n",
      "2022-06-27 16:45:07,031 - mmcls - INFO - Epoch [12][40/74]\tlr: 1.000e-03, eta: 0:06:07, time: 0.141, data_time: 0.049, memory: 737, loss: 3.2882\n",
      "2022-06-27 16:45:08,218 - mmcls - INFO - Epoch [12][50/74]\tlr: 1.000e-03, eta: 0:06:04, time: 0.118, data_time: 0.005, memory: 737, loss: 3.1783\n",
      "2022-06-27 16:45:09,735 - mmcls - INFO - Epoch [12][60/74]\tlr: 1.000e-03, eta: 0:06:01, time: 0.151, data_time: 0.021, memory: 737, loss: 3.2132\n",
      "2022-06-27 16:45:11,018 - mmcls - INFO - Epoch [12][70/74]\tlr: 1.000e-03, eta: 0:05:59, time: 0.129, data_time: 0.023, memory: 737, loss: 3.2848\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 559.6 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:45:15,094 - mmcls - INFO - Epoch(val) [12][32]\tmAP: 50.0761, ACC: 0.8995\n",
      "2022-06-27 16:45:19,176 - mmcls - INFO - Epoch [13][10/74]\tlr: 1.000e-03, eta: 0:06:00, time: 0.405, data_time: 0.303, memory: 737, loss: 2.9870\n",
      "2022-06-27 16:45:20,714 - mmcls - INFO - Epoch [13][20/74]\tlr: 1.000e-03, eta: 0:05:58, time: 0.156, data_time: 0.088, memory: 737, loss: 3.2892\n",
      "2022-06-27 16:45:22,014 - mmcls - INFO - Epoch [13][30/74]\tlr: 1.000e-03, eta: 0:05:55, time: 0.128, data_time: 0.049, memory: 737, loss: 3.2457\n",
      "2022-06-27 16:45:23,794 - mmcls - INFO - Epoch [13][40/74]\tlr: 1.000e-03, eta: 0:05:53, time: 0.180, data_time: 0.117, memory: 737, loss: 3.1620\n",
      "2022-06-27 16:45:25,153 - mmcls - INFO - Epoch [13][50/74]\tlr: 1.000e-03, eta: 0:05:51, time: 0.134, data_time: 0.002, memory: 737, loss: 3.1441\n",
      "2022-06-27 16:45:26,743 - mmcls - INFO - Epoch [13][60/74]\tlr: 1.000e-03, eta: 0:05:49, time: 0.161, data_time: 0.007, memory: 737, loss: 3.2706\n",
      "2022-06-27 16:45:27,958 - mmcls - INFO - Epoch [13][70/74]\tlr: 1.000e-03, eta: 0:05:46, time: 0.121, data_time: 0.003, memory: 737, loss: 3.2373\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 565.6 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:45:31,767 - mmcls - INFO - Epoch(val) [13][32]\tmAP: 50.5824, ACC: 0.9005\n",
      "2022-06-27 16:45:35,580 - mmcls - INFO - Epoch [14][10/74]\tlr: 1.000e-03, eta: 0:05:46, time: 0.378, data_time: 0.310, memory: 737, loss: 3.1165\n",
      "2022-06-27 16:45:36,993 - mmcls - INFO - Epoch [14][20/74]\tlr: 1.000e-03, eta: 0:05:44, time: 0.144, data_time: 0.034, memory: 737, loss: 3.1138\n",
      "2022-06-27 16:45:38,480 - mmcls - INFO - Epoch [14][30/74]\tlr: 1.000e-03, eta: 0:05:42, time: 0.145, data_time: 0.017, memory: 737, loss: 3.0649\n",
      "2022-06-27 16:45:40,234 - mmcls - INFO - Epoch [14][40/74]\tlr: 1.000e-03, eta: 0:05:40, time: 0.178, data_time: 0.076, memory: 737, loss: 3.3174\n",
      "2022-06-27 16:45:41,820 - mmcls - INFO - Epoch [14][50/74]\tlr: 1.000e-03, eta: 0:05:38, time: 0.159, data_time: 0.003, memory: 737, loss: 3.1138\n",
      "2022-06-27 16:45:43,032 - mmcls - INFO - Epoch [14][60/74]\tlr: 1.000e-03, eta: 0:05:35, time: 0.119, data_time: 0.001, memory: 737, loss: 3.1494\n",
      "2022-06-27 16:45:44,330 - mmcls - INFO - Epoch [14][70/74]\tlr: 1.000e-03, eta: 0:05:33, time: 0.132, data_time: 0.061, memory: 737, loss: 3.2113\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 555.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:45:48,225 - mmcls - INFO - Epoch(val) [14][32]\tmAP: 51.2584, ACC: 0.9020\n",
      "2022-06-27 16:45:52,503 - mmcls - INFO - Epoch [15][10/74]\tlr: 1.000e-03, eta: 0:05:34, time: 0.426, data_time: 0.284, memory: 737, loss: 3.2425\n",
      "2022-06-27 16:45:54,152 - mmcls - INFO - Epoch [15][20/74]\tlr: 1.000e-03, eta: 0:05:32, time: 0.165, data_time: 0.002, memory: 737, loss: 3.1209\n",
      "2022-06-27 16:45:55,340 - mmcls - INFO - Epoch [15][30/74]\tlr: 1.000e-03, eta: 0:05:29, time: 0.117, data_time: 0.011, memory: 737, loss: 3.1025\n",
      "2022-06-27 16:45:57,032 - mmcls - INFO - Epoch [15][40/74]\tlr: 1.000e-03, eta: 0:05:27, time: 0.171, data_time: 0.031, memory: 737, loss: 3.0689\n",
      "2022-06-27 16:45:58,656 - mmcls - INFO - Epoch [15][50/74]\tlr: 1.000e-03, eta: 0:05:25, time: 0.163, data_time: 0.015, memory: 737, loss: 3.0264\n",
      "2022-06-27 16:46:00,061 - mmcls - INFO - Epoch [15][60/74]\tlr: 1.000e-03, eta: 0:05:23, time: 0.139, data_time: 0.003, memory: 737, loss: 3.0941\n",
      "2022-06-27 16:46:01,217 - mmcls - INFO - Epoch [15][70/74]\tlr: 1.000e-03, eta: 0:05:20, time: 0.116, data_time: 0.003, memory: 737, loss: 3.2290\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 560.1 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:46:05,036 - mmcls - INFO - Epoch(val) [15][32]\tmAP: 51.4404, ACC: 0.9032\n",
      "2022-06-27 16:46:09,376 - mmcls - INFO - Epoch [16][10/74]\tlr: 1.000e-03, eta: 0:05:21, time: 0.433, data_time: 0.297, memory: 737, loss: 3.2972\n",
      "2022-06-27 16:46:10,598 - mmcls - INFO - Epoch [16][20/74]\tlr: 1.000e-03, eta: 0:05:18, time: 0.123, data_time: 0.052, memory: 737, loss: 2.9799\n",
      "2022-06-27 16:46:12,286 - mmcls - INFO - Epoch [16][30/74]\tlr: 1.000e-03, eta: 0:05:17, time: 0.168, data_time: 0.103, memory: 737, loss: 2.9865\n",
      "2022-06-27 16:46:13,238 - mmcls - INFO - Epoch [16][40/74]\tlr: 1.000e-03, eta: 0:05:14, time: 0.095, data_time: 0.008, memory: 737, loss: 3.0427\n",
      "2022-06-27 16:46:14,849 - mmcls - INFO - Epoch [16][50/74]\tlr: 1.000e-03, eta: 0:05:12, time: 0.157, data_time: 0.054, memory: 737, loss: 3.0279\n",
      "2022-06-27 16:46:16,406 - mmcls - INFO - Epoch [16][60/74]\tlr: 1.000e-03, eta: 0:05:10, time: 0.157, data_time: 0.080, memory: 737, loss: 3.1630\n",
      "2022-06-27 16:46:17,614 - mmcls - INFO - Epoch [16][70/74]\tlr: 1.000e-03, eta: 0:05:07, time: 0.123, data_time: 0.049, memory: 737, loss: 3.3104\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 559.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:46:21,646 - mmcls - INFO - Epoch(val) [16][32]\tmAP: 52.1775, ACC: 0.9042\n",
      "2022-06-27 16:46:25,761 - mmcls - INFO - Epoch [17][10/74]\tlr: 1.000e-03, eta: 0:05:07, time: 0.411, data_time: 0.343, memory: 737, loss: 3.0987\n",
      "2022-06-27 16:46:27,413 - mmcls - INFO - Epoch [17][20/74]\tlr: 1.000e-03, eta: 0:05:05, time: 0.164, data_time: 0.093, memory: 737, loss: 3.0821\n",
      "2022-06-27 16:46:28,671 - mmcls - INFO - Epoch [17][30/74]\tlr: 1.000e-03, eta: 0:05:03, time: 0.126, data_time: 0.058, memory: 737, loss: 3.0159\n",
      "2022-06-27 16:46:30,402 - mmcls - INFO - Epoch [17][40/74]\tlr: 1.000e-03, eta: 0:05:01, time: 0.172, data_time: 0.067, memory: 737, loss: 2.9301\n",
      "2022-06-27 16:46:31,530 - mmcls - INFO - Epoch [17][50/74]\tlr: 1.000e-03, eta: 0:04:59, time: 0.115, data_time: 0.013, memory: 737, loss: 3.1198\n",
      "2022-06-27 16:46:33,109 - mmcls - INFO - Epoch [17][60/74]\tlr: 1.000e-03, eta: 0:04:57, time: 0.158, data_time: 0.001, memory: 737, loss: 3.0478\n",
      "2022-06-27 16:46:34,367 - mmcls - INFO - Epoch [17][70/74]\tlr: 1.000e-03, eta: 0:04:54, time: 0.125, data_time: 0.026, memory: 737, loss: 3.1115\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 549.5 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:46:38,605 - mmcls - INFO - Epoch(val) [17][32]\tmAP: 52.8828, ACC: 0.9046\n",
      "2022-06-27 16:46:42,780 - mmcls - INFO - Epoch [18][10/74]\tlr: 1.000e-03, eta: 0:04:54, time: 0.417, data_time: 0.228, memory: 737, loss: 2.8679\n",
      "2022-06-27 16:46:44,010 - mmcls - INFO - Epoch [18][20/74]\tlr: 1.000e-03, eta: 0:04:52, time: 0.122, data_time: 0.004, memory: 737, loss: 3.2451\n",
      "2022-06-27 16:46:45,437 - mmcls - INFO - Epoch [18][30/74]\tlr: 1.000e-03, eta: 0:04:50, time: 0.143, data_time: 0.003, memory: 737, loss: 3.1458\n",
      "2022-06-27 16:46:47,286 - mmcls - INFO - Epoch [18][40/74]\tlr: 1.000e-03, eta: 0:04:48, time: 0.185, data_time: 0.003, memory: 737, loss: 3.1161\n",
      "2022-06-27 16:46:48,259 - mmcls - INFO - Epoch [18][50/74]\tlr: 1.000e-03, eta: 0:04:45, time: 0.098, data_time: 0.015, memory: 737, loss: 3.0850\n",
      "2022-06-27 16:46:50,132 - mmcls - INFO - Epoch [18][60/74]\tlr: 1.000e-03, eta: 0:04:44, time: 0.183, data_time: 0.001, memory: 737, loss: 2.9193\n",
      "2022-06-27 16:46:52,102 - mmcls - INFO - Epoch [18][70/74]\tlr: 1.000e-03, eta: 0:04:42, time: 0.201, data_time: 0.008, memory: 737, loss: 3.1086\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 560.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:46:56,005 - mmcls - INFO - Epoch(val) [18][32]\tmAP: 53.4042, ACC: 0.9054\n",
      "2022-06-27 16:46:59,901 - mmcls - INFO - Epoch [19][10/74]\tlr: 1.000e-03, eta: 0:04:42, time: 0.387, data_time: 0.294, memory: 737, loss: 3.0028\n",
      "2022-06-27 16:47:01,616 - mmcls - INFO - Epoch [19][20/74]\tlr: 1.000e-03, eta: 0:04:40, time: 0.170, data_time: 0.111, memory: 737, loss: 3.0942\n",
      "2022-06-27 16:47:02,913 - mmcls - INFO - Epoch [19][30/74]\tlr: 1.000e-03, eta: 0:04:38, time: 0.130, data_time: 0.005, memory: 737, loss: 2.9401\n",
      "2022-06-27 16:47:04,530 - mmcls - INFO - Epoch [19][40/74]\tlr: 1.000e-03, eta: 0:04:36, time: 0.165, data_time: 0.030, memory: 737, loss: 3.1624\n",
      "2022-06-27 16:47:06,166 - mmcls - INFO - Epoch [19][50/74]\tlr: 1.000e-03, eta: 0:04:34, time: 0.160, data_time: 0.091, memory: 737, loss: 2.9068\n",
      "2022-06-27 16:47:07,601 - mmcls - INFO - Epoch [19][60/74]\tlr: 1.000e-03, eta: 0:04:32, time: 0.143, data_time: 0.068, memory: 737, loss: 3.0792\n",
      "2022-06-27 16:47:09,008 - mmcls - INFO - Epoch [19][70/74]\tlr: 1.000e-03, eta: 0:04:30, time: 0.143, data_time: 0.024, memory: 737, loss: 3.0778\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 568.3 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:47:12,884 - mmcls - INFO - Epoch(val) [19][32]\tmAP: 53.7289, ACC: 0.9066\n",
      "2022-06-27 16:47:16,933 - mmcls - INFO - Epoch [20][10/74]\tlr: 1.000e-03, eta: 0:04:29, time: 0.402, data_time: 0.248, memory: 737, loss: 2.9591\n",
      "2022-06-27 16:47:18,713 - mmcls - INFO - Epoch [20][20/74]\tlr: 1.000e-03, eta: 0:04:27, time: 0.179, data_time: 0.081, memory: 737, loss: 3.1019\n",
      "2022-06-27 16:47:20,324 - mmcls - INFO - Epoch [20][30/74]\tlr: 1.000e-03, eta: 0:04:25, time: 0.162, data_time: 0.066, memory: 737, loss: 3.0547\n",
      "2022-06-27 16:47:21,621 - mmcls - INFO - Epoch [20][40/74]\tlr: 1.000e-03, eta: 0:04:23, time: 0.130, data_time: 0.061, memory: 737, loss: 2.9651\n",
      "2022-06-27 16:47:22,885 - mmcls - INFO - Epoch [20][50/74]\tlr: 1.000e-03, eta: 0:04:21, time: 0.125, data_time: 0.029, memory: 737, loss: 3.0028\n",
      "2022-06-27 16:47:24,344 - mmcls - INFO - Epoch [20][60/74]\tlr: 1.000e-03, eta: 0:04:19, time: 0.147, data_time: 0.030, memory: 737, loss: 2.9595\n",
      "2022-06-27 16:47:25,756 - mmcls - INFO - Epoch [20][70/74]\tlr: 1.000e-03, eta: 0:04:17, time: 0.140, data_time: 0.002, memory: 737, loss: 2.9890\n",
      "2022-06-27 16:47:25,981 - mmcls - INFO - Saving checkpoint at 20 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 590.2 task/s, elapsed: 3s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:47:29,680 - mmcls - INFO - Epoch(val) [20][32]\tmAP: 53.9575, ACC: 0.9058\n",
      "2022-06-27 16:47:33,605 - mmcls - INFO - Epoch [21][10/74]\tlr: 1.000e-04, eta: 0:04:16, time: 0.391, data_time: 0.228, memory: 737, loss: 2.9697\n",
      "2022-06-27 16:47:35,209 - mmcls - INFO - Epoch [21][20/74]\tlr: 1.000e-04, eta: 0:04:14, time: 0.160, data_time: 0.003, memory: 737, loss: 3.0468\n",
      "2022-06-27 16:47:37,113 - mmcls - INFO - Epoch [21][30/74]\tlr: 1.000e-04, eta: 0:04:12, time: 0.190, data_time: 0.003, memory: 737, loss: 2.8309\n",
      "2022-06-27 16:47:38,496 - mmcls - INFO - Epoch [21][40/74]\tlr: 1.000e-04, eta: 0:04:10, time: 0.137, data_time: 0.003, memory: 737, loss: 3.1321\n",
      "2022-06-27 16:47:39,973 - mmcls - INFO - Epoch [21][50/74]\tlr: 1.000e-04, eta: 0:04:08, time: 0.148, data_time: 0.004, memory: 737, loss: 2.9447\n",
      "2022-06-27 16:47:41,638 - mmcls - INFO - Epoch [21][60/74]\tlr: 1.000e-04, eta: 0:04:07, time: 0.168, data_time: 0.080, memory: 737, loss: 3.0330\n",
      "2022-06-27 16:47:42,653 - mmcls - INFO - Epoch [21][70/74]\tlr: 1.000e-04, eta: 0:04:04, time: 0.101, data_time: 0.010, memory: 737, loss: 2.9645\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 554.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:47:46,698 - mmcls - INFO - Epoch(val) [21][32]\tmAP: 54.0527, ACC: 0.9065\n",
      "2022-06-27 16:47:51,104 - mmcls - INFO - Epoch [22][10/74]\tlr: 1.000e-04, eta: 0:04:03, time: 0.440, data_time: 0.356, memory: 737, loss: 2.8924\n",
      "2022-06-27 16:47:52,285 - mmcls - INFO - Epoch [22][20/74]\tlr: 1.000e-04, eta: 0:04:01, time: 0.117, data_time: 0.052, memory: 737, loss: 2.9611\n",
      "2022-06-27 16:47:54,311 - mmcls - INFO - Epoch [22][30/74]\tlr: 1.000e-04, eta: 0:04:00, time: 0.203, data_time: 0.140, memory: 737, loss: 3.1956\n",
      "2022-06-27 16:47:55,281 - mmcls - INFO - Epoch [22][40/74]\tlr: 1.000e-04, eta: 0:03:57, time: 0.096, data_time: 0.028, memory: 737, loss: 2.9302\n",
      "2022-06-27 16:47:56,734 - mmcls - INFO - Epoch [22][50/74]\tlr: 1.000e-04, eta: 0:03:55, time: 0.146, data_time: 0.052, memory: 737, loss: 3.1003\n",
      "2022-06-27 16:47:58,616 - mmcls - INFO - Epoch [22][60/74]\tlr: 1.000e-04, eta: 0:03:54, time: 0.187, data_time: 0.120, memory: 737, loss: 2.9425\n",
      "2022-06-27 16:47:59,545 - mmcls - INFO - Epoch [22][70/74]\tlr: 1.000e-04, eta: 0:03:51, time: 0.095, data_time: 0.019, memory: 737, loss: 2.9361\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 568.9 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:48:03,427 - mmcls - INFO - Epoch(val) [22][32]\tmAP: 54.0359, ACC: 0.9070\n",
      "2022-06-27 16:48:07,429 - mmcls - INFO - Epoch [23][10/74]\tlr: 1.000e-04, eta: 0:03:50, time: 0.400, data_time: 0.331, memory: 737, loss: 2.9244\n",
      "2022-06-27 16:48:08,889 - mmcls - INFO - Epoch [23][20/74]\tlr: 1.000e-04, eta: 0:03:48, time: 0.146, data_time: 0.083, memory: 737, loss: 2.9994\n",
      "2022-06-27 16:48:10,175 - mmcls - INFO - Epoch [23][30/74]\tlr: 1.000e-04, eta: 0:03:46, time: 0.128, data_time: 0.032, memory: 737, loss: 2.8984\n",
      "2022-06-27 16:48:11,881 - mmcls - INFO - Epoch [23][40/74]\tlr: 1.000e-04, eta: 0:03:44, time: 0.171, data_time: 0.002, memory: 737, loss: 3.0298\n",
      "2022-06-27 16:48:13,105 - mmcls - INFO - Epoch [23][50/74]\tlr: 1.000e-04, eta: 0:03:42, time: 0.121, data_time: 0.002, memory: 737, loss: 2.9668\n",
      "2022-06-27 16:48:15,340 - mmcls - INFO - Epoch [23][60/74]\tlr: 1.000e-04, eta: 0:03:41, time: 0.224, data_time: 0.002, memory: 737, loss: 3.0107\n",
      "2022-06-27 16:48:16,488 - mmcls - INFO - Epoch [23][70/74]\tlr: 1.000e-04, eta: 0:03:39, time: 0.116, data_time: 0.002, memory: 737, loss: 2.9894\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 566.2 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:48:20,445 - mmcls - INFO - Epoch(val) [23][32]\tmAP: 54.1561, ACC: 0.9066\n",
      "2022-06-27 16:48:24,324 - mmcls - INFO - Epoch [24][10/74]\tlr: 1.000e-04, eta: 0:03:37, time: 0.386, data_time: 0.282, memory: 737, loss: 3.0095\n",
      "2022-06-27 16:48:25,783 - mmcls - INFO - Epoch [24][20/74]\tlr: 1.000e-04, eta: 0:03:35, time: 0.147, data_time: 0.068, memory: 737, loss: 2.8953\n",
      "2022-06-27 16:48:27,722 - mmcls - INFO - Epoch [24][30/74]\tlr: 1.000e-04, eta: 0:03:34, time: 0.194, data_time: 0.071, memory: 737, loss: 2.9392\n",
      "2022-06-27 16:48:28,918 - mmcls - INFO - Epoch [24][40/74]\tlr: 1.000e-04, eta: 0:03:32, time: 0.118, data_time: 0.001, memory: 737, loss: 2.9403\n",
      "2022-06-27 16:48:30,281 - mmcls - INFO - Epoch [24][50/74]\tlr: 1.000e-04, eta: 0:03:30, time: 0.136, data_time: 0.003, memory: 737, loss: 2.9465\n",
      "2022-06-27 16:48:31,846 - mmcls - INFO - Epoch [24][60/74]\tlr: 1.000e-04, eta: 0:03:28, time: 0.157, data_time: 0.085, memory: 737, loss: 3.0279\n",
      "2022-06-27 16:48:33,211 - mmcls - INFO - Epoch [24][70/74]\tlr: 1.000e-04, eta: 0:03:26, time: 0.138, data_time: 0.005, memory: 737, loss: 2.8982\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 562.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:48:37,050 - mmcls - INFO - Epoch(val) [24][32]\tmAP: 54.1643, ACC: 0.9071\n",
      "2022-06-27 16:48:41,182 - mmcls - INFO - Epoch [25][10/74]\tlr: 1.000e-04, eta: 0:03:24, time: 0.412, data_time: 0.235, memory: 737, loss: 2.9061\n",
      "2022-06-27 16:48:42,797 - mmcls - INFO - Epoch [25][20/74]\tlr: 1.000e-04, eta: 0:03:23, time: 0.162, data_time: 0.027, memory: 737, loss: 2.8906\n",
      "2022-06-27 16:48:43,932 - mmcls - INFO - Epoch [25][30/74]\tlr: 1.000e-04, eta: 0:03:20, time: 0.113, data_time: 0.043, memory: 737, loss: 2.9719\n",
      "2022-06-27 16:48:45,301 - mmcls - INFO - Epoch [25][40/74]\tlr: 1.000e-04, eta: 0:03:18, time: 0.138, data_time: 0.064, memory: 737, loss: 3.0359\n",
      "2022-06-27 16:48:46,958 - mmcls - INFO - Epoch [25][50/74]\tlr: 1.000e-04, eta: 0:03:17, time: 0.164, data_time: 0.094, memory: 737, loss: 2.9410\n",
      "2022-06-27 16:48:48,576 - mmcls - INFO - Epoch [25][60/74]\tlr: 1.000e-04, eta: 0:03:15, time: 0.163, data_time: 0.009, memory: 737, loss: 2.9824\n",
      "2022-06-27 16:48:50,154 - mmcls - INFO - Epoch [25][70/74]\tlr: 1.000e-04, eta: 0:03:13, time: 0.157, data_time: 0.042, memory: 737, loss: 3.0213\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 558.3 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:48:53,984 - mmcls - INFO - Epoch(val) [25][32]\tmAP: 54.1517, ACC: 0.9069\n",
      "2022-06-27 16:48:57,994 - mmcls - INFO - Epoch [26][10/74]\tlr: 1.000e-04, eta: 0:03:11, time: 0.400, data_time: 0.277, memory: 737, loss: 3.0198\n",
      "2022-06-27 16:48:59,396 - mmcls - INFO - Epoch [26][20/74]\tlr: 1.000e-04, eta: 0:03:10, time: 0.139, data_time: 0.022, memory: 737, loss: 2.9962\n",
      "2022-06-27 16:49:00,877 - mmcls - INFO - Epoch [26][30/74]\tlr: 1.000e-04, eta: 0:03:08, time: 0.146, data_time: 0.075, memory: 737, loss: 3.1615\n",
      "2022-06-27 16:49:02,436 - mmcls - INFO - Epoch [26][40/74]\tlr: 1.000e-04, eta: 0:03:06, time: 0.158, data_time: 0.007, memory: 737, loss: 2.9317\n",
      "2022-06-27 16:49:03,887 - mmcls - INFO - Epoch [26][50/74]\tlr: 1.000e-04, eta: 0:03:04, time: 0.144, data_time: 0.002, memory: 737, loss: 2.8501\n",
      "2022-06-27 16:49:05,403 - mmcls - INFO - Epoch [26][60/74]\tlr: 1.000e-04, eta: 0:03:02, time: 0.153, data_time: 0.003, memory: 737, loss: 3.0201\n",
      "2022-06-27 16:49:06,881 - mmcls - INFO - Epoch [26][70/74]\tlr: 1.000e-04, eta: 0:03:00, time: 0.148, data_time: 0.002, memory: 737, loss: 2.9134\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 561.9 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:49:10,877 - mmcls - INFO - Epoch(val) [26][32]\tmAP: 54.3101, ACC: 0.9070\n",
      "2022-06-27 16:49:14,751 - mmcls - INFO - Epoch [27][10/74]\tlr: 1.000e-04, eta: 0:02:58, time: 0.386, data_time: 0.269, memory: 737, loss: 2.8990\n",
      "2022-06-27 16:49:16,134 - mmcls - INFO - Epoch [27][20/74]\tlr: 1.000e-04, eta: 0:02:57, time: 0.139, data_time: 0.002, memory: 737, loss: 2.9355\n",
      "2022-06-27 16:49:17,932 - mmcls - INFO - Epoch [27][30/74]\tlr: 1.000e-04, eta: 0:02:55, time: 0.180, data_time: 0.036, memory: 737, loss: 2.9704\n",
      "2022-06-27 16:49:19,465 - mmcls - INFO - Epoch [27][40/74]\tlr: 1.000e-04, eta: 0:02:53, time: 0.153, data_time: 0.001, memory: 737, loss: 2.8819\n",
      "2022-06-27 16:49:21,073 - mmcls - INFO - Epoch [27][50/74]\tlr: 1.000e-04, eta: 0:02:51, time: 0.160, data_time: 0.078, memory: 737, loss: 3.0215\n",
      "2022-06-27 16:49:22,649 - mmcls - INFO - Epoch [27][60/74]\tlr: 1.000e-04, eta: 0:02:49, time: 0.157, data_time: 0.029, memory: 737, loss: 2.9778\n",
      "2022-06-27 16:49:24,283 - mmcls - INFO - Epoch [27][70/74]\tlr: 1.000e-04, eta: 0:02:48, time: 0.165, data_time: 0.006, memory: 737, loss: 2.8547\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 562.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:49:28,131 - mmcls - INFO - Epoch(val) [27][32]\tmAP: 54.2223, ACC: 0.9074\n",
      "2022-06-27 16:49:32,253 - mmcls - INFO - Epoch [28][10/74]\tlr: 1.000e-04, eta: 0:02:46, time: 0.410, data_time: 0.346, memory: 737, loss: 2.9544\n",
      "2022-06-27 16:49:34,363 - mmcls - INFO - Epoch [28][20/74]\tlr: 1.000e-04, eta: 0:02:44, time: 0.212, data_time: 0.027, memory: 737, loss: 2.9456\n",
      "2022-06-27 16:49:35,545 - mmcls - INFO - Epoch [28][30/74]\tlr: 1.000e-04, eta: 0:02:42, time: 0.118, data_time: 0.003, memory: 737, loss: 3.1236\n",
      "2022-06-27 16:49:37,067 - mmcls - INFO - Epoch [28][40/74]\tlr: 1.000e-04, eta: 0:02:40, time: 0.152, data_time: 0.052, memory: 737, loss: 2.8985\n",
      "2022-06-27 16:49:38,507 - mmcls - INFO - Epoch [28][50/74]\tlr: 1.000e-04, eta: 0:02:39, time: 0.144, data_time: 0.041, memory: 737, loss: 2.8965\n",
      "2022-06-27 16:49:40,178 - mmcls - INFO - Epoch [28][60/74]\tlr: 1.000e-04, eta: 0:02:37, time: 0.167, data_time: 0.066, memory: 737, loss: 2.9921\n",
      "2022-06-27 16:49:41,214 - mmcls - INFO - Epoch [28][70/74]\tlr: 1.000e-04, eta: 0:02:35, time: 0.103, data_time: 0.002, memory: 737, loss: 2.9634\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 561.8 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:49:45,169 - mmcls - INFO - Epoch(val) [28][32]\tmAP: 54.2522, ACC: 0.9075\n",
      "2022-06-27 16:49:49,373 - mmcls - INFO - Epoch [29][10/74]\tlr: 1.000e-04, eta: 0:02:33, time: 0.417, data_time: 0.323, memory: 737, loss: 2.9318\n",
      "2022-06-27 16:49:50,671 - mmcls - INFO - Epoch [29][20/74]\tlr: 1.000e-04, eta: 0:02:31, time: 0.132, data_time: 0.061, memory: 737, loss: 2.9066\n",
      "2022-06-27 16:49:52,131 - mmcls - INFO - Epoch [29][30/74]\tlr: 1.000e-04, eta: 0:02:29, time: 0.147, data_time: 0.051, memory: 737, loss: 2.9819\n",
      "2022-06-27 16:49:53,796 - mmcls - INFO - Epoch [29][40/74]\tlr: 1.000e-04, eta: 0:02:28, time: 0.167, data_time: 0.013, memory: 737, loss: 2.9866\n",
      "2022-06-27 16:49:54,900 - mmcls - INFO - Epoch [29][50/74]\tlr: 1.000e-04, eta: 0:02:25, time: 0.109, data_time: 0.003, memory: 737, loss: 2.8415\n",
      "2022-06-27 16:49:56,414 - mmcls - INFO - Epoch [29][60/74]\tlr: 1.000e-04, eta: 0:02:24, time: 0.151, data_time: 0.003, memory: 737, loss: 2.9578\n",
      "2022-06-27 16:49:57,825 - mmcls - INFO - Epoch [29][70/74]\tlr: 1.000e-04, eta: 0:02:22, time: 0.141, data_time: 0.002, memory: 737, loss: 3.0306\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 549.6 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:50:02,056 - mmcls - INFO - Epoch(val) [29][32]\tmAP: 54.3299, ACC: 0.9073\n",
      "2022-06-27 16:50:06,189 - mmcls - INFO - Epoch [30][10/74]\tlr: 1.000e-04, eta: 0:02:20, time: 0.412, data_time: 0.294, memory: 737, loss: 3.0757\n",
      "2022-06-27 16:50:07,493 - mmcls - INFO - Epoch [30][20/74]\tlr: 1.000e-04, eta: 0:02:18, time: 0.131, data_time: 0.029, memory: 737, loss: 3.0755\n",
      "2022-06-27 16:50:09,215 - mmcls - INFO - Epoch [30][30/74]\tlr: 1.000e-04, eta: 0:02:16, time: 0.171, data_time: 0.068, memory: 737, loss: 2.9645\n",
      "2022-06-27 16:50:10,486 - mmcls - INFO - Epoch [30][40/74]\tlr: 1.000e-04, eta: 0:02:14, time: 0.125, data_time: 0.015, memory: 737, loss: 2.9346\n",
      "2022-06-27 16:50:12,148 - mmcls - INFO - Epoch [30][50/74]\tlr: 1.000e-04, eta: 0:02:13, time: 0.169, data_time: 0.005, memory: 737, loss: 2.8706\n",
      "2022-06-27 16:50:13,588 - mmcls - INFO - Epoch [30][60/74]\tlr: 1.000e-04, eta: 0:02:11, time: 0.142, data_time: 0.001, memory: 737, loss: 2.9925\n",
      "2022-06-27 16:50:14,800 - mmcls - INFO - Epoch [30][70/74]\tlr: 1.000e-04, eta: 0:02:09, time: 0.123, data_time: 0.047, memory: 737, loss: 2.8549\n",
      "2022-06-27 16:50:15,200 - mmcls - INFO - Saving checkpoint at 30 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 586.0 task/s, elapsed: 3s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:50:18,918 - mmcls - INFO - Epoch(val) [30][32]\tmAP: 54.3805, ACC: 0.9078\n",
      "2022-06-27 16:50:23,025 - mmcls - INFO - Epoch [31][10/74]\tlr: 1.000e-04, eta: 0:02:07, time: 0.410, data_time: 0.277, memory: 737, loss: 2.8302\n",
      "2022-06-27 16:50:24,482 - mmcls - INFO - Epoch [31][20/74]\tlr: 1.000e-04, eta: 0:02:05, time: 0.146, data_time: 0.011, memory: 737, loss: 3.0921\n",
      "2022-06-27 16:50:26,096 - mmcls - INFO - Epoch [31][30/74]\tlr: 1.000e-04, eta: 0:02:03, time: 0.159, data_time: 0.056, memory: 737, loss: 3.0257\n",
      "2022-06-27 16:50:27,767 - mmcls - INFO - Epoch [31][40/74]\tlr: 1.000e-04, eta: 0:02:02, time: 0.169, data_time: 0.054, memory: 737, loss: 2.9620\n",
      "2022-06-27 16:50:29,077 - mmcls - INFO - Epoch [31][50/74]\tlr: 1.000e-04, eta: 0:02:00, time: 0.130, data_time: 0.040, memory: 737, loss: 2.8787\n",
      "2022-06-27 16:50:30,327 - mmcls - INFO - Epoch [31][60/74]\tlr: 1.000e-04, eta: 0:01:58, time: 0.125, data_time: 0.045, memory: 737, loss: 2.9720\n",
      "2022-06-27 16:50:31,615 - mmcls - INFO - Epoch [31][70/74]\tlr: 1.000e-04, eta: 0:01:56, time: 0.129, data_time: 0.049, memory: 737, loss: 2.8960\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 562.5 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:50:35,477 - mmcls - INFO - Epoch(val) [31][32]\tmAP: 54.3470, ACC: 0.9078\n",
      "2022-06-27 16:50:39,562 - mmcls - INFO - Epoch [32][10/74]\tlr: 1.000e-04, eta: 0:01:54, time: 0.407, data_time: 0.261, memory: 737, loss: 2.9124\n",
      "2022-06-27 16:50:41,081 - mmcls - INFO - Epoch [32][20/74]\tlr: 1.000e-04, eta: 0:01:52, time: 0.152, data_time: 0.004, memory: 737, loss: 2.9462\n",
      "2022-06-27 16:50:42,938 - mmcls - INFO - Epoch [32][30/74]\tlr: 1.000e-04, eta: 0:01:50, time: 0.187, data_time: 0.003, memory: 737, loss: 2.8219\n",
      "2022-06-27 16:50:44,316 - mmcls - INFO - Epoch [32][40/74]\tlr: 1.000e-04, eta: 0:01:49, time: 0.134, data_time: 0.008, memory: 737, loss: 2.9140\n",
      "2022-06-27 16:50:45,310 - mmcls - INFO - Epoch [32][50/74]\tlr: 1.000e-04, eta: 0:01:47, time: 0.101, data_time: 0.005, memory: 737, loss: 3.0280\n",
      "2022-06-27 16:50:47,021 - mmcls - INFO - Epoch [32][60/74]\tlr: 1.000e-04, eta: 0:01:45, time: 0.172, data_time: 0.082, memory: 737, loss: 2.9891\n",
      "2022-06-27 16:50:48,209 - mmcls - INFO - Epoch [32][70/74]\tlr: 1.000e-04, eta: 0:01:43, time: 0.118, data_time: 0.002, memory: 737, loss: 2.9822\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 562.9 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:50:52,260 - mmcls - INFO - Epoch(val) [32][32]\tmAP: 54.5561, ACC: 0.9079\n",
      "2022-06-27 16:50:56,333 - mmcls - INFO - Epoch [33][10/74]\tlr: 1.000e-04, eta: 0:01:41, time: 0.406, data_time: 0.330, memory: 737, loss: 2.9859\n",
      "2022-06-27 16:50:57,881 - mmcls - INFO - Epoch [33][20/74]\tlr: 1.000e-04, eta: 0:01:39, time: 0.154, data_time: 0.049, memory: 737, loss: 3.0637\n",
      "2022-06-27 16:50:59,541 - mmcls - INFO - Epoch [33][30/74]\tlr: 1.000e-04, eta: 0:01:37, time: 0.166, data_time: 0.002, memory: 737, loss: 3.0425\n",
      "2022-06-27 16:51:00,951 - mmcls - INFO - Epoch [33][40/74]\tlr: 1.000e-04, eta: 0:01:36, time: 0.141, data_time: 0.003, memory: 737, loss: 2.8020\n",
      "2022-06-27 16:51:02,151 - mmcls - INFO - Epoch [33][50/74]\tlr: 1.000e-04, eta: 0:01:34, time: 0.119, data_time: 0.005, memory: 737, loss: 2.8472\n",
      "2022-06-27 16:51:03,944 - mmcls - INFO - Epoch [33][60/74]\tlr: 1.000e-04, eta: 0:01:32, time: 0.180, data_time: 0.003, memory: 737, loss: 2.7810\n",
      "2022-06-27 16:51:05,184 - mmcls - INFO - Epoch [33][70/74]\tlr: 1.000e-04, eta: 0:01:30, time: 0.123, data_time: 0.002, memory: 737, loss: 3.0657\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 564.6 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:51:09,063 - mmcls - INFO - Epoch(val) [33][32]\tmAP: 54.4655, ACC: 0.9073\n",
      "2022-06-27 16:51:13,245 - mmcls - INFO - Epoch [34][10/74]\tlr: 1.000e-04, eta: 0:01:28, time: 0.416, data_time: 0.264, memory: 737, loss: 2.9828\n",
      "2022-06-27 16:51:14,536 - mmcls - INFO - Epoch [34][20/74]\tlr: 1.000e-04, eta: 0:01:26, time: 0.130, data_time: 0.024, memory: 737, loss: 2.9204\n",
      "2022-06-27 16:51:15,929 - mmcls - INFO - Epoch [34][30/74]\tlr: 1.000e-04, eta: 0:01:24, time: 0.139, data_time: 0.047, memory: 737, loss: 2.9572\n",
      "2022-06-27 16:51:17,610 - mmcls - INFO - Epoch [34][40/74]\tlr: 1.000e-04, eta: 0:01:23, time: 0.169, data_time: 0.007, memory: 737, loss: 2.9095\n",
      "2022-06-27 16:51:19,340 - mmcls - INFO - Epoch [34][50/74]\tlr: 1.000e-04, eta: 0:01:21, time: 0.173, data_time: 0.004, memory: 737, loss: 2.9788\n",
      "2022-06-27 16:51:20,444 - mmcls - INFO - Epoch [34][60/74]\tlr: 1.000e-04, eta: 0:01:19, time: 0.107, data_time: 0.017, memory: 737, loss: 2.8982\n",
      "2022-06-27 16:51:21,652 - mmcls - INFO - Epoch [34][70/74]\tlr: 1.000e-04, eta: 0:01:17, time: 0.124, data_time: 0.029, memory: 737, loss: 2.9691\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 559.8 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:51:25,676 - mmcls - INFO - Epoch(val) [34][32]\tmAP: 54.4437, ACC: 0.9073\n",
      "2022-06-27 16:51:29,880 - mmcls - INFO - Epoch [35][10/74]\tlr: 1.000e-04, eta: 0:01:15, time: 0.419, data_time: 0.251, memory: 737, loss: 3.0046\n",
      "2022-06-27 16:51:31,318 - mmcls - INFO - Epoch [35][20/74]\tlr: 1.000e-04, eta: 0:01:13, time: 0.145, data_time: 0.002, memory: 737, loss: 2.8340\n",
      "2022-06-27 16:51:32,873 - mmcls - INFO - Epoch [35][30/74]\tlr: 1.000e-04, eta: 0:01:12, time: 0.153, data_time: 0.001, memory: 737, loss: 2.9953\n",
      "2022-06-27 16:51:34,604 - mmcls - INFO - Epoch [35][40/74]\tlr: 1.000e-04, eta: 0:01:10, time: 0.175, data_time: 0.004, memory: 737, loss: 2.9475\n",
      "2022-06-27 16:51:35,969 - mmcls - INFO - Epoch [35][50/74]\tlr: 1.000e-04, eta: 0:01:08, time: 0.137, data_time: 0.003, memory: 737, loss: 2.9766\n",
      "2022-06-27 16:51:37,539 - mmcls - INFO - Epoch [35][60/74]\tlr: 1.000e-04, eta: 0:01:06, time: 0.158, data_time: 0.001, memory: 737, loss: 2.8249\n",
      "2022-06-27 16:51:38,542 - mmcls - INFO - Epoch [35][70/74]\tlr: 1.000e-04, eta: 0:01:04, time: 0.099, data_time: 0.001, memory: 737, loss: 3.0504\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 568.7 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:51:42,445 - mmcls - INFO - Epoch(val) [35][32]\tmAP: 54.5854, ACC: 0.9078\n",
      "2022-06-27 16:51:46,421 - mmcls - INFO - Epoch [36][10/74]\tlr: 1.000e-04, eta: 0:01:02, time: 0.396, data_time: 0.235, memory: 737, loss: 2.9608\n",
      "2022-06-27 16:51:48,198 - mmcls - INFO - Epoch [36][20/74]\tlr: 1.000e-04, eta: 0:01:00, time: 0.178, data_time: 0.004, memory: 737, loss: 2.9081\n",
      "2022-06-27 16:51:49,697 - mmcls - INFO - Epoch [36][30/74]\tlr: 1.000e-04, eta: 0:00:59, time: 0.150, data_time: 0.002, memory: 737, loss: 3.0146\n",
      "2022-06-27 16:51:50,912 - mmcls - INFO - Epoch [36][40/74]\tlr: 1.000e-04, eta: 0:00:57, time: 0.120, data_time: 0.004, memory: 737, loss: 2.9408\n",
      "2022-06-27 16:51:52,580 - mmcls - INFO - Epoch [36][50/74]\tlr: 1.000e-04, eta: 0:00:55, time: 0.163, data_time: 0.059, memory: 737, loss: 2.9650\n",
      "2022-06-27 16:51:54,089 - mmcls - INFO - Epoch [36][60/74]\tlr: 1.000e-04, eta: 0:00:53, time: 0.156, data_time: 0.074, memory: 737, loss: 2.9534\n",
      "2022-06-27 16:51:55,212 - mmcls - INFO - Epoch [36][70/74]\tlr: 1.000e-04, eta: 0:00:52, time: 0.112, data_time: 0.049, memory: 737, loss: 3.0029\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 559.3 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:51:59,134 - mmcls - INFO - Epoch(val) [36][32]\tmAP: 54.4838, ACC: 0.9079\n",
      "2022-06-27 16:52:03,059 - mmcls - INFO - Epoch [37][10/74]\tlr: 1.000e-04, eta: 0:00:49, time: 0.392, data_time: 0.241, memory: 737, loss: 3.0075\n",
      "2022-06-27 16:52:04,911 - mmcls - INFO - Epoch [37][20/74]\tlr: 1.000e-04, eta: 0:00:48, time: 0.183, data_time: 0.002, memory: 737, loss: 2.8502\n",
      "2022-06-27 16:52:06,085 - mmcls - INFO - Epoch [37][30/74]\tlr: 1.000e-04, eta: 0:00:46, time: 0.119, data_time: 0.004, memory: 737, loss: 2.8834\n",
      "2022-06-27 16:52:07,652 - mmcls - INFO - Epoch [37][40/74]\tlr: 1.000e-04, eta: 0:00:44, time: 0.155, data_time: 0.004, memory: 737, loss: 2.9519\n",
      "2022-06-27 16:52:09,240 - mmcls - INFO - Epoch [37][50/74]\tlr: 1.000e-04, eta: 0:00:42, time: 0.159, data_time: 0.004, memory: 737, loss: 2.9548\n",
      "2022-06-27 16:52:10,529 - mmcls - INFO - Epoch [37][60/74]\tlr: 1.000e-04, eta: 0:00:40, time: 0.129, data_time: 0.030, memory: 737, loss: 2.8519\n",
      "2022-06-27 16:52:11,830 - mmcls - INFO - Epoch [37][70/74]\tlr: 1.000e-04, eta: 0:00:39, time: 0.131, data_time: 0.007, memory: 737, loss: 2.9935\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 560.8 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:52:15,813 - mmcls - INFO - Epoch(val) [37][32]\tmAP: 54.5525, ACC: 0.9078\n",
      "2022-06-27 16:52:19,990 - mmcls - INFO - Epoch [38][10/74]\tlr: 1.000e-04, eta: 0:00:36, time: 0.415, data_time: 0.236, memory: 737, loss: 2.9220\n",
      "2022-06-27 16:52:21,396 - mmcls - INFO - Epoch [38][20/74]\tlr: 1.000e-04, eta: 0:00:35, time: 0.139, data_time: 0.005, memory: 737, loss: 2.9446\n",
      "2022-06-27 16:52:23,034 - mmcls - INFO - Epoch [38][30/74]\tlr: 1.000e-04, eta: 0:00:33, time: 0.166, data_time: 0.091, memory: 737, loss: 2.9691\n",
      "2022-06-27 16:52:24,608 - mmcls - INFO - Epoch [38][40/74]\tlr: 1.000e-04, eta: 0:00:31, time: 0.157, data_time: 0.040, memory: 737, loss: 2.9099\n",
      "2022-06-27 16:52:25,852 - mmcls - INFO - Epoch [38][50/74]\tlr: 1.000e-04, eta: 0:00:29, time: 0.124, data_time: 0.015, memory: 737, loss: 2.7715\n",
      "2022-06-27 16:52:27,218 - mmcls - INFO - Epoch [38][60/74]\tlr: 1.000e-04, eta: 0:00:28, time: 0.135, data_time: 0.042, memory: 737, loss: 2.8417\n",
      "2022-06-27 16:52:28,787 - mmcls - INFO - Epoch [38][70/74]\tlr: 1.000e-04, eta: 0:00:26, time: 0.159, data_time: 0.093, memory: 737, loss: 3.0752\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 564.3 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:52:32,670 - mmcls - INFO - Epoch(val) [38][32]\tmAP: 54.7140, ACC: 0.9079\n",
      "2022-06-27 16:52:36,692 - mmcls - INFO - Epoch [39][10/74]\tlr: 1.000e-04, eta: 0:00:24, time: 0.401, data_time: 0.325, memory: 737, loss: 2.9274\n",
      "2022-06-27 16:52:38,461 - mmcls - INFO - Epoch [39][20/74]\tlr: 1.000e-04, eta: 0:00:22, time: 0.177, data_time: 0.116, memory: 737, loss: 2.8253\n",
      "2022-06-27 16:52:39,648 - mmcls - INFO - Epoch [39][30/74]\tlr: 1.000e-04, eta: 0:00:20, time: 0.120, data_time: 0.040, memory: 737, loss: 3.0300\n",
      "2022-06-27 16:52:41,183 - mmcls - INFO - Epoch [39][40/74]\tlr: 1.000e-04, eta: 0:00:18, time: 0.153, data_time: 0.036, memory: 737, loss: 2.9539\n",
      "2022-06-27 16:52:42,736 - mmcls - INFO - Epoch [39][50/74]\tlr: 1.000e-04, eta: 0:00:17, time: 0.155, data_time: 0.004, memory: 737, loss: 2.7751\n",
      "2022-06-27 16:52:44,331 - mmcls - INFO - Epoch [39][60/74]\tlr: 1.000e-04, eta: 0:00:15, time: 0.160, data_time: 0.001, memory: 737, loss: 2.8274\n",
      "2022-06-27 16:52:45,510 - mmcls - INFO - Epoch [39][70/74]\tlr: 1.000e-04, eta: 0:00:13, time: 0.117, data_time: 0.004, memory: 737, loss: 2.9765\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 560.5 task/s, elapsed: 4s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:52:49,568 - mmcls - INFO - Epoch(val) [39][32]\tmAP: 54.6311, ACC: 0.9076\n",
      "2022-06-27 16:52:53,722 - mmcls - INFO - Epoch [40][10/74]\tlr: 1.000e-04, eta: 0:00:11, time: 0.413, data_time: 0.345, memory: 737, loss: 2.9275\n",
      "2022-06-27 16:52:54,951 - mmcls - INFO - Epoch [40][20/74]\tlr: 1.000e-04, eta: 0:00:09, time: 0.123, data_time: 0.033, memory: 737, loss: 2.8838\n",
      "2022-06-27 16:52:56,448 - mmcls - INFO - Epoch [40][30/74]\tlr: 1.000e-04, eta: 0:00:07, time: 0.151, data_time: 0.003, memory: 737, loss: 2.9764\n",
      "2022-06-27 16:52:58,120 - mmcls - INFO - Epoch [40][40/74]\tlr: 1.000e-04, eta: 0:00:05, time: 0.165, data_time: 0.099, memory: 737, loss: 2.8798\n",
      "2022-06-27 16:52:59,167 - mmcls - INFO - Epoch [40][50/74]\tlr: 1.000e-04, eta: 0:00:04, time: 0.106, data_time: 0.034, memory: 737, loss: 2.7467\n",
      "2022-06-27 16:53:00,733 - mmcls - INFO - Epoch [40][60/74]\tlr: 1.000e-04, eta: 0:00:02, time: 0.154, data_time: 0.003, memory: 737, loss: 3.0825\n",
      "2022-06-27 16:53:02,122 - mmcls - INFO - Epoch [40][70/74]\tlr: 1.000e-04, eta: 0:00:00, time: 0.141, data_time: 0.030, memory: 737, loss: 2.9201\n",
      "2022-06-27 16:53:02,645 - mmcls - INFO - Saving checkpoint at 40 epochs\n",
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2005/2005, 594.4 task/s, elapsed: 3s, ETA:     0s\n",
      "\n",
      "2022-06-27 16:53:06,320 - mmcls - INFO - Epoch(val) [40][32]\tmAP: 54.6403, ACC: 0.9081\n"
     ]
    }
   ],
   "source": [
    "!mmclassification/tools/dist_train.sh {config_path} {num_gpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmcls.datasets.pipelines import Compose\n",
    "\n",
    "def inference_model(model, img):\n",
    "    \"\"\"Inference image(s) with the classifier.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded classifier.\n",
    "        img (str/ndarray): The image filename or loaded image.\n",
    "    \"\"\"\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "    # build the data pipeline\n",
    "    if isinstance(img, str):\n",
    "        if cfg.data.test.pipeline[0]['type'] != 'LoadImageFromFile':\n",
    "            cfg.data.test.pipeline.insert(0, dict(type='LoadImageFromFile'))\n",
    "        data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "    else:\n",
    "        if cfg.data.test.pipeline[0]['type'] == 'LoadImageFromFile':\n",
    "            cfg.data.test.pipeline.pop(0)\n",
    "        data = dict(img=img)\n",
    "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "    data = test_pipeline(data)\n",
    "    data = collate([data], samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "\n",
    "    # forward the model\n",
    "    with torch.no_grad():\n",
    "        scores = model(return_loss=False, **data)[0]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/hli5/miniconda3/envs/food2022/lib/python3.8/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/mobile_v3_l_4xb16_foodseg103/latest.pth\n",
      "Accuracy of Meat: 0.8429471643238002\n",
      "Accuracy of Nuts/seeds: 0.971885603490063\n",
      "Accuracy of Eggs: 0.968007755695589\n",
      "Accuracy of Beans/lentils/peas: 0.9781871061560834\n",
      "Accuracy of Fruit: 0.8720310227823558\n",
      "Accuracy of Grain: 0.7348521570528357\n",
      "Accuracy of Vegetables: 0.8962675714978187\n",
      "Accuracy of Dairy: 0.9209888511875909\n",
      "Accuracy of Dessert: 0.8768783325254483\n",
      "Accuracy of Sauce/Spread: 0.8768783325254483\n",
      "Accuracy of Soup: 0.9883664566165778\n",
      "Accuracy of Drink: 0.9476490547746\n",
      "0.9062449507190177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mmcls.apis import init_model\n",
    "import torch as torch\n",
    "import glob\n",
    "import mmcv\n",
    "labels_db = pd.read_csv(\"food103labels.csv\",sep=',')\n",
    "model = init_model(config_path, checkpoint_file, device='cuda')\n",
    "LABELS = list(model.CLASSES)\n",
    "np_acc = np.zeros(len(LABELS))\n",
    "count = 0\n",
    "file_list = glob.glob(\"FoodSeg103/Images/img_dir/test/*\")\n",
    "all_predictions = np.zeros(shape=(len(file_list), len(LABELS)))\n",
    "all_gt = np.zeros(shape=(len(file_list), len(LABELS)))\n",
    "def get_label(file_path):    \n",
    "    file_name = file_path.split('/')[-1]\n",
    "    numpy_array = labels_db.loc[labels_db['filename'] == file_name][LABELS].to_numpy().astype('int64')\n",
    "    return numpy_array\n",
    "for file in file_list:\n",
    "    img_array =  mmcv.imread(file)\n",
    "    preds = inference_model(model, file)\n",
    "    preds[preds>=0.5] = 1\n",
    "    preds[preds<0.5] = 0\n",
    "    all_predictions[count, :] = preds\n",
    "    gt_label = get_label(file).squeeze()\n",
    "    all_gt[count, :] = gt_label\n",
    "    np_acc = np.add(preds == gt_label, np_acc)\n",
    "    count+=1\n",
    "    print(count, end='\\r')\n",
    "np_acc = np_acc/len(file_list)\n",
    "c = 0\n",
    "for l in LABELS:\n",
    "    print(f\"Accuracy of {l}: {np_acc[c]}\")\n",
    "    c = c+1\n",
    "print(np.average(np_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.42146227207164\n"
     ]
    }
   ],
   "source": [
    "from mmseg.core.evaluation import mean_ap\n",
    "\n",
    "mean_average_precision = mean_ap.mAP(all_predictions, all_gt)\n",
    "print(mean_average_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('food2022': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ceed115e2785451e93a6892c02d3760f831f2e8ebb6fa3a261251c7741db1606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
