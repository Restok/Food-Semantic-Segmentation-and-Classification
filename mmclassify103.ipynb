{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "num_gpus = 4\n",
    "classes = (\"Meat\", \"Nuts/seeds\", \"Eggs\", \"Beans/lentils/peas\", \"Fruit\", \"Grain\", \"Vegetables\", \"Dairy\", \"Sauce/Spread\", \"Soup/Drink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile('mmclassification/configs/resnet/resnet101_4xb16_foodseg103.py')\n",
    "name = \"mobile_v3_l_4xb16_combined\"\n",
    "import os\n",
    "work_dir = './work_dirs/' + name\n",
    "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n",
    "if(not osp.exists(checkpoint_file)):\n",
    "    checkpoint_file = 'https://download.openmmlab.com/mmclassification/v0/mobilenet_v3/convert/mobilenet_v3_large-3ea3c186.pth'\n",
    "    print(\"Loading pretrained weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'FoodSeg103'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='RandomResizedCrop', size=224),\n",
      "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='ToTensor', keys=['gt_label']),\n",
      "    dict(type='Collect', keys=['img', 'gt_label'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='Resize', size=(256, -1)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='ImageToTensor', keys=['img']),\n",
      "    dict(type='Collect', keys=['img'])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=16,\n",
      "    workers_per_gpu=4,\n",
      "    train=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/train.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='RandomResizedCrop', size=224),\n",
      "            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='ToTensor', keys=['gt_label']),\n",
      "            dict(type='Collect', keys=['img', 'gt_label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/test.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', size=(256, -1)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='FoodSeg103',\n",
      "        data_prefix='FoodSeg103Classification/data',\n",
      "        ann_file='FoodSeg103Classification/data/test.txt',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='Resize', size=(256, -1)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric=['mAP', 'ACC'])\n",
      "checkpoint_config = dict(interval=10)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='ImageClassifier',\n",
      "    backbone=dict(\n",
      "        type='MobileNetV3',\n",
      "        arch='large',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='./work_dirs/mobile_v3_l_4xb16_combined/latest.pth',\n",
      "            prefix='backbone')),\n",
      "    neck=dict(type='GlobalAveragePooling'),\n",
      "    head=dict(\n",
      "        type='MultiLabelLinearClsHead',\n",
      "        num_classes=10,\n",
      "        in_channels=960,\n",
      "        loss=dict(type='CrossEntropyLoss', loss_weight=1.0, use_sigmoid=True)))\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    lr=0.001,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict({'.backbone.classifier': dict(lr_mult=10)})))\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(policy='step', step=20, gamma=0.1)\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.model.head.num_classes = len(classes)\n",
    "\n",
    "# Load the pre-trained model's checkpoint.\n",
    "cfg.model.backbone = dict(type='MobileNetV3', arch='large')\n",
    "cfg.model.backbone['init_cfg'] = dict(type='Pretrained', checkpoint=checkpoint_file, prefix='backbone')\n",
    "cfg.model.head.in_channels=960\n",
    "\n",
    "# Specify sample size and number of workers.\n",
    "cfg.data.samples_per_gpu = 16\n",
    "cfg.checkpoint_config = dict(interval=10)\n",
    "cfg.log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
    "cfg.data.workers_per_gpu = 4\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=40)\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n",
    "config_path = \"mmclassification/configs/food103configs/\" + name + \".py\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"mmclassification/tools/dist_train.sh {config_path} {num_gpus}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mmclassification/tools/dist_train.sh {config_path} {num_gpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = os.path.join(work_dir, \"latest.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmcls.datasets.pipelines import Compose\n",
    "\n",
    "def inference_model(model, img):\n",
    "    \"\"\"Inference image(s) with the classifier.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The loaded classifier.\n",
    "        img (str/ndarray): The image filename or loaded image.\n",
    "    \"\"\"\n",
    "    cfg = model.cfg\n",
    "    device = next(model.parameters()).device  # model device\n",
    "    # build the data pipeline\n",
    "    if isinstance(img, str):\n",
    "        if cfg.data.test.pipeline[0]['type'] != 'LoadImageFromFile':\n",
    "            cfg.data.test.pipeline.insert(0, dict(type='LoadImageFromFile'))\n",
    "        data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "    else:\n",
    "        if cfg.data.test.pipeline[0]['type'] == 'LoadImageFromFile':\n",
    "            cfg.data.test.pipeline.pop(0)\n",
    "        data = dict(img=img)\n",
    "    test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "    data = test_pipeline(data)\n",
    "    data = collate([data], samples_per_gpu=1)\n",
    "    if next(model.parameters()).is_cuda:\n",
    "        # scatter to specified GPU\n",
    "        data = scatter(data, [device])[0]\n",
    "\n",
    "    # forward the model\n",
    "    with torch.no_grad():\n",
    "        scores = model(return_loss=False, **data)[0]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/hli5/miniconda3/envs/openmmlab/lib/python3.8/site-packages/mmcv/cnn/bricks/hsigmoid.py:31: UserWarning: In MMCV v1.4.4, we modified the default value of args to align with PyTorch official. Previous Implementation: Hsigmoid(x) = min(max((x + 1) / 2, 0), 1). Current Implementation: Hsigmoid(x) = min(max((x + 3) / 6, 0), 1).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/mobile_v3_l_4xb16_combined/latest.pth\n",
      "2009\r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mmcls.apis import init_model\n",
    "import torch as torch\n",
    "import glob\n",
    "import mmcv\n",
    "labels_db = pd.read_csv(\"food103labels.csv\",sep=',')\n",
    "model = init_model(config_path, checkpoint_file, device='cuda:0')\n",
    "LABELS = list(model.CLASSES)\n",
    "np_acc = np.zeros(len(LABELS))\n",
    "count = 0\n",
    "file_list = glob.glob(\"SegCombined/Images/img_dir/test/*\")\n",
    "all_predictions = np.zeros(shape=(len(file_list), len(LABELS)))\n",
    "all_gt = np.zeros(shape=(len(file_list), len(LABELS)))\n",
    "def get_label(file_path):    \n",
    "    file_name = file_path.split('/')[-1]\n",
    "    numpy_array = labels_db.loc[labels_db['filename'] == file_name][LABELS].to_numpy().astype('int64')\n",
    "    return numpy_array\n",
    "for file in file_list:\n",
    "    img_array =  mmcv.imread(file)\n",
    "    preds = inference_model(model, file)\n",
    "    all_predictions[count, :] = preds\n",
    "    gt_label = get_label(file).squeeze()\n",
    "    all_gt[count, :] = gt_label\n",
    "    count+=1\n",
    "    print(count, end='\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92547863 0.49709374 0.38146654 0.08173596 0.86636094 0.84972295\n",
      " 0.98252312 0.63917717 0.53379831 0.73247498]\n",
      "0.6489832341851518\n"
     ]
    }
   ],
   "source": [
    "from mmseg.core.evaluation import mean_ap\n",
    "\n",
    "mean_average_precision = mean_ap.mAP(all_predictions, all_gt)\n",
    "print(mean_average_precision)\n",
    "print(mean_average_precision.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84967646 0.95968143 0.95520159 0.97859632 0.8765555  0.77003484\n",
      " 0.89696366 0.86311598 0.87356894 0.93081135]\n",
      "0.8954206072672971\n"
     ]
    }
   ],
   "source": [
    "all_predictions[all_predictions>=0.5] = 1\n",
    "all_predictions[all_predictions<0.5] = 0\n",
    "\n",
    "acc = (all_predictions==all_gt).sum(axis=0)\n",
    "acc = acc/len(file_list)\n",
    "for i in range(len(LABELS)):\n",
    "    print(f\"Accuracy of {LABELS[i]}: {acc[i]}\")\n",
    "print(acc.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('openmmlab': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2df9c0ab135fefd9e1d5771bb661da9405eccfda404ab5b76dcd4eec0f509788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
